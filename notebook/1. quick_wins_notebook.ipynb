{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6464f308",
   "metadata": {},
   "source": [
    "## üì¶ Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a06e01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q sentence-transformers faiss-cpu FlagEmbedding rank-bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ba895",
   "metadata": {},
   "source": [
    "## üìö Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db6730ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "# Embedding & Retrieval\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Reranking\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "# BM25\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Utils\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4660e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f4b7e",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4a017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n",
      "  data_dir: ../data\n",
      "  output_file: submission_improved.csv\n",
      "  embedding_model: BAAI/bge-large-en-v1.5\n",
      "  reranker_model: BAAI/bge-reranker-v2-m3\n",
      "  use_chunking: True\n",
      "  chunk_size: 512\n",
      "  chunk_overlap: 128\n",
      "  chunk_aggregation: max\n",
      "  preserve_tables: True\n",
      "  use_hybrid: True\n",
      "  hybrid_alpha: 0.6\n",
      "  top_k_retrieval: 100\n",
      "  top_k_rerank: 50\n",
      "  top_k_final: 10\n",
      "  embed_batch_size: 16\n",
      "  rerank_batch_size: 16\n",
      "  max_length: 512\n",
      "  eval_on_qrels: True\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    'data_dir': '../data',\n",
    "    'output_file': 'submission_improved.csv',\n",
    "    \n",
    "    'datasets': [\n",
    "        'convfinqa', 'financebench', 'finder',\n",
    "        'finqa', 'finqabench', 'multiheirtt', 'tatqa'\n",
    "    ],\n",
    "    \n",
    "    # Models - UPGRADED\n",
    "    'embedding_model': 'BAAI/bge-large-en-v1.5',\n",
    "    'reranker_model': 'BAAI/bge-reranker-v2-m3',\n",
    "    \n",
    "    # Chunking - NEW\n",
    "    'use_chunking': True,\n",
    "    'chunk_size': 512,\n",
    "    'chunk_overlap': 128,\n",
    "    'chunk_aggregation': 'max',\n",
    "    'preserve_tables': True,\n",
    "    \n",
    "    # Hybrid - NEW\n",
    "    'use_hybrid': True,\n",
    "    'hybrid_alpha': 0.6,\n",
    "    \n",
    "    # Parameters - INCREASED\n",
    "    'top_k_retrieval': 100,  # from 50\n",
    "    'top_k_rerank': 50,\n",
    "    'top_k_final': 10,\n",
    "    \n",
    "    'embed_batch_size': 16,\n",
    "    'rerank_batch_size': 16,\n",
    "    'max_length': 512,\n",
    "    \n",
    "    'eval_on_qrels': True,\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "for k, v in CONFIG.items():\n",
    "    if k != 'datasets':\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ba17a",
   "metadata": {},
   "source": [
    "## üîß Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f771e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_data(dataset_name: str, data_dir: str):\n",
    "    \"\"\"Load corpus, queries, and qrels\"\"\"\n",
    "    corpus_path = os.path.join(data_dir, f\"{dataset_name}_corpus.jsonl\", \"corpus.jsonl\")\n",
    "    queries_path = os.path.join(data_dir, f\"{dataset_name}_queries.jsonl\", \"queries.jsonl\")\n",
    "    qrels_path = os.path.join(data_dir, f\"{dataset_name}_qrels.tsv\")\n",
    "    \n",
    "    corpus_df = pd.read_json(corpus_path, lines=True)\n",
    "    queries_df = pd.read_json(queries_path, lines=True)\n",
    "    \n",
    "    qrels_df = None\n",
    "    if os.path.exists(qrels_path):\n",
    "        qrels_df = pd.read_csv(qrels_path, sep='\\t')\n",
    "    \n",
    "    print(f\"  Loaded {len(corpus_df)} docs, {len(queries_df)} queries\")\n",
    "    return corpus_df, queries_df, qrels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e51df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tables(text: str) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Detect table regions using heuristics\"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    table_regions = []\n",
    "    in_table = False\n",
    "    table_start = 0\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        is_table = (\n",
    "            line.count('|') >= 2 or\n",
    "            line.count('\\t') >= 2 or\n",
    "            len(re.findall(r'\\s{3,}', line)) >= 2\n",
    "        )\n",
    "        \n",
    "        if is_table and not in_table:\n",
    "            in_table = True\n",
    "            table_start = max(0, i - 1)\n",
    "        elif not is_table and in_table:\n",
    "            in_table = False\n",
    "            table_end = min(len(lines), i + 1)\n",
    "            if table_end - table_start >= 3:\n",
    "                table_regions.append((table_start, table_end))\n",
    "    \n",
    "    if in_table:\n",
    "        table_regions.append((table_start, len(lines)))\n",
    "    \n",
    "    return table_regions\n",
    "\n",
    "\n",
    "def chunk_text_simple(text: str, chunk_size: int, overlap: int) -> List[str]:\n",
    "    \"\"\"Sliding window chunking\"\"\"\n",
    "    words = text.split()\n",
    "    if len(words) <= chunk_size:\n",
    "        return [text]\n",
    "    \n",
    "    chunks = []\n",
    "    step = chunk_size - overlap\n",
    "    for i in range(0, len(words), step):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        if len(words[i:i + chunk_size]) >= 50:\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def chunk_document_smart(doc_id: str, title: str, text: str, \n",
    "                        chunk_size: int, overlap: int, preserve_tables: bool):\n",
    "    \"\"\"Smart chunking with table preservation\"\"\"\n",
    "    chunks = []\n",
    "    \n",
    "    if not preserve_tables or len(text) < 500:\n",
    "        for i, chunk_text in enumerate(chunk_text_simple(text, chunk_size, overlap)):\n",
    "            chunks.append({\n",
    "                'chunk_id': f\"{doc_id}_c{i}\",\n",
    "                'text': f\"[{title}] {chunk_text}\",\n",
    "                'doc_id': doc_id\n",
    "            })\n",
    "        return chunks\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    table_regions = detect_tables(text)\n",
    "    \n",
    "    if not table_regions:\n",
    "        for i, chunk_text in enumerate(chunk_text_simple(text, chunk_size, overlap)):\n",
    "            chunks.append({\n",
    "                'chunk_id': f\"{doc_id}_c{i}\",\n",
    "                'text': f\"[{title}] {chunk_text}\",\n",
    "                'doc_id': doc_id\n",
    "            })\n",
    "        return chunks\n",
    "    \n",
    "    chunk_idx = 0\n",
    "    prev_end = 0\n",
    "    \n",
    "    for table_start, table_end in table_regions:\n",
    "        # Text before table\n",
    "        if table_start > prev_end:\n",
    "            before = '\\n'.join(lines[prev_end:table_start])\n",
    "            if before.strip():\n",
    "                for chunk_text in chunk_text_simple(before, chunk_size, overlap):\n",
    "                    chunks.append({\n",
    "                        'chunk_id': f\"{doc_id}_c{chunk_idx}\",\n",
    "                        'text': f\"[{title}] {chunk_text}\",\n",
    "                        'doc_id': doc_id\n",
    "                    })\n",
    "                    chunk_idx += 1\n",
    "        \n",
    "        # Table as single chunk\n",
    "        table_text = '\\n'.join(lines[table_start:table_end])\n",
    "        chunks.append({\n",
    "            'chunk_id': f\"{doc_id}_t{chunk_idx}\",\n",
    "            'text': f\"[TABLE from {title}]\\n{table_text}\",\n",
    "            'doc_id': doc_id\n",
    "        })\n",
    "        chunk_idx += 1\n",
    "        prev_end = table_end\n",
    "    \n",
    "    # Text after table\n",
    "    if prev_end < len(lines):\n",
    "        after = '\\n'.join(lines[prev_end:])\n",
    "        if after.strip():\n",
    "            for chunk_text in chunk_text_simple(after, chunk_size, overlap):\n",
    "                chunks.append({\n",
    "                    'chunk_id': f\"{doc_id}_c{chunk_idx}\",\n",
    "                    'text': f\"[{title}] {chunk_text}\",\n",
    "                    'doc_id': doc_id\n",
    "                })\n",
    "                chunk_idx += 1\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4078534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(scores: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize to [0, 1]\"\"\"\n",
    "    if scores.max() == scores.min():\n",
    "        return np.ones_like(scores)\n",
    "    return (scores - scores.min()) / (scores.max() - scores.min())\n",
    "\n",
    "\n",
    "def hybrid_search(query_emb, query_text, faiss_index, bm25, corpus_texts, top_k, alpha=0.6):\n",
    "    \"\"\"Hybrid: Dense + BM25\"\"\"\n",
    "    # Dense\n",
    "    dense_scores, indices = faiss_index.search(\n",
    "        query_emb.reshape(1, -1).astype('float32'), top_k * 2\n",
    "    )\n",
    "    dense_scores = dense_scores[0]\n",
    "    indices = indices[0]\n",
    "    \n",
    "    # BM25\n",
    "    query_tokens = query_text.lower().split()\n",
    "    bm25_scores = bm25.get_scores(query_tokens)\n",
    "    bm25_subset = bm25_scores[indices]\n",
    "    \n",
    "    # Normalize\n",
    "    dense_norm = normalize_scores(dense_scores)\n",
    "    bm25_norm = normalize_scores(bm25_subset)\n",
    "    \n",
    "    # Combine\n",
    "    hybrid = alpha * dense_norm + (1 - alpha) * bm25_norm\n",
    "    \n",
    "    # Re-sort\n",
    "    sorted_idx = np.argsort(hybrid)[::-1][:top_k]\n",
    "    return hybrid[sorted_idx], indices[sorted_idx]\n",
    "\n",
    "\n",
    "def aggregate_chunk_scores(chunk_scores: Dict, method='max') -> Dict:\n",
    "    \"\"\"Aggregate chunk scores to doc scores\"\"\"\n",
    "    aggregated = {}\n",
    "    for doc_id, scores in chunk_scores.items():\n",
    "        if method == 'max':\n",
    "            aggregated[doc_id] = max(scores)\n",
    "        elif method == 'mean':\n",
    "            aggregated[doc_id] = np.mean(scores)\n",
    "        elif method == 'weighted':\n",
    "            weights = np.array([1.0 / (i + 1) for i in range(len(scores))])\n",
    "            weights = weights / weights.sum()\n",
    "            aggregated[doc_id] = np.dot(scores, weights)\n",
    "        else:\n",
    "            aggregated[doc_id] = max(scores)\n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82a59762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndcg(qrels: Dict, results: Dict, k=10) -> float:\n",
    "    \"\"\"Compute NDCG@k\"\"\"\n",
    "    ndcg_scores = []\n",
    "    for query_id, retrieved in results.items():\n",
    "        if query_id not in qrels:\n",
    "            continue\n",
    "        \n",
    "        relevant = qrels[query_id]\n",
    "        retrieved_k = retrieved[:k]\n",
    "        \n",
    "        # DCG\n",
    "        dcg = sum(relevant.get(doc_id, 0) / np.log2(i + 2) \n",
    "                  for i, doc_id in enumerate(retrieved_k))\n",
    "        \n",
    "        # IDCG\n",
    "        ideal = sorted(relevant.values(), reverse=True)[:k]\n",
    "        idcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(ideal))\n",
    "        \n",
    "        if idcg > 0:\n",
    "            ndcg_scores.append(dcg / idcg)\n",
    "    \n",
    "    return np.mean(ndcg_scores) if ndcg_scores else 0.0\n",
    "\n",
    "\n",
    "def evaluate_results(results_df, qrels_df, k=10):\n",
    "    \"\"\"Evaluate with qrels\"\"\"\n",
    "    qrels = qrels_df.groupby('query_id').apply(\n",
    "        lambda x: dict(zip(x['corpus_id'], x['score']))\n",
    "    ).to_dict()\n",
    "    \n",
    "    results = results_df.groupby('query_id')['corpus_id'].apply(list).to_dict()\n",
    "    \n",
    "    ndcg = compute_ndcg(qrels, results, k)\n",
    "    return {'NDCG@10': ndcg, 'num_queries': len(results), 'num_qrels': len(qrels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f7127",
   "metadata": {},
   "source": [
    "## ü§ñ Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f19ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "\n",
      "1. Loading: BAAI/bge-large-en-v1.5\n",
      "   ‚úÖ Done\n",
      "\n",
      "2. Loading: BAAI/bge-reranker-v2-m3\n",
      "   ‚úÖ Done\n",
      "\n",
      "‚úÖ All models loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading models...\")\n",
    "\n",
    "# Embedding\n",
    "print(f\"\\n1. Loading: {CONFIG['embedding_model']}\")\n",
    "embed_model = SentenceTransformer(CONFIG['embedding_model'], device=device)\n",
    "print(\"   ‚úÖ Done\")\n",
    "\n",
    "# Reranker\n",
    "print(f\"\\n2. Loading: {CONFIG['reranker_model']}\")\n",
    "reranker = FlagReranker(CONFIG['reranker_model'], use_fp16=(device=='cuda'))\n",
    "print(\"   ‚úÖ Done\")\n",
    "\n",
    "print(\"\\n‚úÖ All models loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f410e",
   "metadata": {},
   "source": [
    "## üîÑ Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5375cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_improved(dataset_name: str, config: Dict):\n",
    "    \"\"\"Improved pipeline\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {dataset_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load\n",
    "    corpus_df, queries_df, qrels_df = load_jsonl_data(dataset_name, config['data_dir'])\n",
    "    \n",
    "    # Chunk\n",
    "    print(f\"\\nüìÑ Chunking...\")\n",
    "    all_chunks = []\n",
    "    chunk_to_doc = {}\n",
    "    \n",
    "    if config['use_chunking']:\n",
    "        for _, row in tqdm(corpus_df.iterrows(), total=len(corpus_df), desc=\"Chunk\"):\n",
    "            chunks = chunk_document_smart(\n",
    "                row['_id'], str(row.get('title', '')), str(row.get('text', '')),\n",
    "                config['chunk_size'], config['chunk_overlap'], config['preserve_tables']\n",
    "            )\n",
    "            for c in chunks:\n",
    "                all_chunks.append(c)\n",
    "                chunk_to_doc[c['chunk_id']] = c['doc_id']\n",
    "        print(f\"   {len(all_chunks)} chunks from {len(corpus_df)} docs\")\n",
    "    else:\n",
    "        for _, row in corpus_df.iterrows():\n",
    "            doc_id = row['_id']\n",
    "            text = f\"[{row.get('title', '')}] {row.get('text', '')}\"\n",
    "            all_chunks.append({'chunk_id': doc_id, 'text': text, 'doc_id': doc_id})\n",
    "            chunk_to_doc[doc_id] = doc_id\n",
    "    \n",
    "    chunk_texts = [c['text'] for c in all_chunks]\n",
    "    chunk_ids = [c['chunk_id'] for c in all_chunks]\n",
    "    \n",
    "    # Embed\n",
    "    print(f\"\\nüî¢ Embedding...\")\n",
    "    chunk_embeddings = embed_model.encode(\n",
    "        chunk_texts, batch_size=config['embed_batch_size'],\n",
    "        show_progress_bar=True, convert_to_numpy=True,\n",
    "        normalize_embeddings=True, max_length=config['max_length']\n",
    "    )\n",
    "    \n",
    "    # FAISS\n",
    "    print(f\"\\nüîç Building FAISS...\")\n",
    "    index = faiss.IndexFlatIP(chunk_embeddings.shape[1])\n",
    "    index.add(chunk_embeddings.astype('float32'))\n",
    "    \n",
    "    # BM25\n",
    "    bm25 = None\n",
    "    if config['use_hybrid']:\n",
    "        print(f\"\\nüî§ Building BM25...\")\n",
    "        tokenized = [t.lower().split() for t in chunk_texts]\n",
    "        bm25 = BM25Okapi(tokenized)\n",
    "    \n",
    "    del chunk_embeddings\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Queries\n",
    "    print(f\"\\nüéØ Processing queries...\")\n",
    "    query_texts = [str(r.get('text', '')) for _, r in queries_df.iterrows()]\n",
    "    query_ids = queries_df['_id'].tolist()\n",
    "    \n",
    "    query_embeddings = embed_model.encode(\n",
    "        query_texts, batch_size=config['embed_batch_size'],\n",
    "        show_progress_bar=True, convert_to_numpy=True,\n",
    "        normalize_embeddings=True, max_length=config['max_length']\n",
    "    )\n",
    "    \n",
    "    # Retrieve\n",
    "    results = []\n",
    "    for i, query_id in enumerate(tqdm(query_ids, desc=\"Retrieve+Rerank\")):\n",
    "        query_emb = query_embeddings[i]\n",
    "        query_text = query_texts[i]\n",
    "        \n",
    "        # Hybrid or dense\n",
    "        if config['use_hybrid'] and bm25:\n",
    "            scores, chunk_indices = hybrid_search(\n",
    "                query_emb, query_text, index, bm25, chunk_texts,\n",
    "                config['top_k_retrieval'], config['hybrid_alpha']\n",
    "            )\n",
    "        else:\n",
    "            scores, chunk_indices = index.search(\n",
    "                query_emb.reshape(1, -1).astype('float32'),\n",
    "                config['top_k_retrieval']\n",
    "            )\n",
    "            scores, chunk_indices = scores[0], chunk_indices[0]\n",
    "        \n",
    "        # Aggregate to docs\n",
    "        doc_scores = {}\n",
    "        for idx, score in zip(chunk_indices, scores):\n",
    "            doc_id = chunk_to_doc[chunk_ids[idx]]\n",
    "            if doc_id not in doc_scores:\n",
    "                doc_scores[doc_id] = []\n",
    "            doc_scores[doc_id].append(float(score))\n",
    "        \n",
    "        doc_agg = aggregate_chunk_scores(doc_scores, config['chunk_aggregation'])\n",
    "        sorted_docs = sorted(doc_agg.items(), key=lambda x: x[1], reverse=True)[:config['top_k_rerank']]\n",
    "        \n",
    "        # Rerank\n",
    "        candidate_ids = [d[0] for d in sorted_docs]\n",
    "        candidate_texts = [\n",
    "            str(corpus_df[corpus_df['_id']==d]['text'].values[0])[:2048]\n",
    "            for d in candidate_ids\n",
    "        ]\n",
    "        \n",
    "        pairs = [[query_text, t] for t in candidate_texts]\n",
    "        rerank_scores = reranker.compute_score(pairs)\n",
    "        \n",
    "        if not isinstance(rerank_scores, list):\n",
    "            rerank_scores = [rerank_scores]\n",
    "        \n",
    "        scored = list(zip(candidate_ids, rerank_scores))\n",
    "        scored.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for doc_id, score in scored[:config['top_k_final']]:\n",
    "            results.append({\n",
    "                'query_id': query_id,\n",
    "                'corpus_id': doc_id,\n",
    "                'score': float(score)\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(f\"\\n‚úÖ Done: {len(results_df)} results\")\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_metrics = {}\n",
    "    if config['eval_on_qrels'] and qrels_df is not None:\n",
    "        print(f\"\\nüìä Evaluating...\")\n",
    "        eval_metrics = evaluate_results(results_df, qrels_df)\n",
    "        print(f\"   NDCG@10: {eval_metrics['NDCG@10']:.4f}\")\n",
    "    \n",
    "    del query_embeddings, index\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return results_df, eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf7ef6",
   "metadata": {},
   "source": [
    "## üöÄ Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bb63896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: CONVFINQA\n",
      "============================================================\n",
      "  Loaded 2066 docs, 421 queries\n",
      "\n",
      "üìÑ Chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2066/2066 [00:00<00:00, 2088.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7473 chunks from 2066 docs\n",
      "\n",
      "üî¢ Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 468/468 [08:23<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS...\n",
      "\n",
      "üî§ Building BM25...\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:02<00:00, 12.51it/s]\n",
      "Retrieve+Rerank: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 421/421 [23:15<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Done: 4210 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.4830\n",
      "\n",
      "============================================================\n",
      "Processing: FINANCEBENCH\n",
      "============================================================\n",
      "  Loaded 180 docs, 150 queries\n",
      "\n",
      "üìÑ Chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180/180 [00:00<00:00, 3806.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   183 chunks from 180 docs\n",
      "\n",
      "üî¢ Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:15<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS...\n",
      "\n",
      "üî§ Building BM25...\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  5.38it/s]\n",
      "Retrieve+Rerank: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [08:11<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Done: 1500 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.3439\n",
      "\n",
      "============================================================\n",
      "Processing: FINDER\n",
      "============================================================\n",
      "  Loaded 13867 docs, 216 queries\n",
      "\n",
      "üìÑ Chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13867/13867 [00:01<00:00, 12599.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13929 chunks from 13867 docs\n",
      "\n",
      "üî¢ Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 871/871 [11:57<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS...\n",
      "\n",
      "üî§ Building BM25...\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:00<00:00, 16.64it/s]\n",
      "Retrieve+Rerank: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 216/216 [11:18<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Done: 2160 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.3612\n",
      "\n",
      "============================================================\n",
      "Processing: FINQA\n",
      "============================================================\n",
      "  Loaded 2789 docs, 1147 queries\n",
      "\n",
      "üìÑ Chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2789/2789 [00:00<00:00, 3890.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10106 chunks from 2789 docs\n",
      "\n",
      "üî¢ Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 632/632 [12:24<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS...\n",
      "\n",
      "üî§ Building BM25...\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72/72 [00:07<00:00, 10.11it/s]\n",
      "Retrieve+Rerank: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1147/1147 [1:03:44<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Done: 11470 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.4382\n",
      "\n",
      "============================================================\n",
      "Processing: FINQABENCH\n",
      "============================================================\n",
      "  Loaded 92 docs, 100 queries\n",
      "\n",
      "üìÑ Chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [00:00<00:00, 5641.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   115 chunks from 92 docs\n",
      "\n",
      "üî¢ Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:06<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS...\n",
      "\n",
      "üî§ Building BM25...\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00,  9.41it/s]\n",
      "Retrieve+Rerank: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [05:28<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Done: 1000 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.8662\n",
      "\n",
      "============================================================\n",
      "Processing: MULTIHEIRTT\n",
      "============================================================\n",
      "  Loaded 10475 docs, 974 queries\n",
      "\n",
      "üìÑ Chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10475/10475 [00:01<00:00, 5316.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23084 chunks from 10475 docs\n",
      "\n",
      "üî¢ Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1443/1443 [32:12<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS...\n",
      "\n",
      "üî§ Building BM25...\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61/61 [00:06<00:00,  9.55it/s]\n",
      "Retrieve+Rerank: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 974/974 [56:43<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Done: 9740 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.1467\n",
      "\n",
      "============================================================\n",
      "Processing: TATQA\n",
      "============================================================\n",
      "  Loaded 2756 docs, 1663 queries\n",
      "\n",
      "üìÑ Chunking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunk: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2756/2756 [00:00<00:00, 5197.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5760 chunks from 2756 docs\n",
      "\n",
      "üî¢ Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 360/360 [06:41<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS...\n",
      "\n",
      "üî§ Building BM25...\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 104/104 [00:08<00:00, 12.82it/s]\n",
      "Retrieve+Rerank: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1663/1663 [5:49:41<00:00, 12.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Done: 16630 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.4935\n",
      "\n",
      "============================================================\n",
      "‚úÖ Done: 7/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "all_eval = {}\n",
    "failed = []\n",
    "\n",
    "for dataset in CONFIG['datasets']:\n",
    "    try:\n",
    "        df_res, metrics = process_dataset_improved(dataset, CONFIG)\n",
    "        all_results.append(df_res)\n",
    "        if metrics:\n",
    "            all_eval[dataset] = metrics\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error: {dataset}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        failed.append(dataset)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Done: {len(all_results)}/{len(CONFIG['datasets'])}\")\n",
    "if failed:\n",
    "    print(f\"‚ùå Failed: {failed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374bbb1",
   "metadata": {},
   "source": [
    "## üìä Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf5f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Local Evaluation (30% qrels):\n",
      "============================================================\n",
      "\n",
      "CONVFINQA: NDCG@10 = 0.4830\n",
      "\n",
      "FINANCEBENCH: NDCG@10 = 0.3439\n",
      "\n",
      "FINDER: NDCG@10 = 0.3612\n",
      "\n",
      "FINQA: NDCG@10 = 0.4382\n",
      "\n",
      "FINQABENCH: NDCG@10 = 0.8662\n",
      "\n",
      "MULTIHEIRTT: NDCG@10 = 0.1467\n",
      "\n",
      "TATQA: NDCG@10 = 0.4935\n",
      "\n",
      "============================================================\n",
      "üìà AVERAGE NDCG@10: 0.4037\n",
      "============================================================\n",
      "\n",
      "üéØ vs Baseline:\n",
      "   Baseline: 0.3280\n",
      "   Improved: 0.4037\n",
      "   Gain: +0.0757 (+23.1%)\n",
      "\n",
      "‚ö†Ô∏è Need more work\n"
     ]
    }
   ],
   "source": [
    "if all_eval:\n",
    "    print(\"\\nüìä Local Evaluation (30% qrels):\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_ndcg = 0\n",
    "    total_queries = 0\n",
    "    \n",
    "    for ds, m in all_eval.items():\n",
    "        print(f\"\\n{ds.upper()}: NDCG@10 = {m['NDCG@10']:.4f}\")\n",
    "        total_ndcg += m['NDCG@10'] * m['num_qrels']\n",
    "        total_queries += m['num_qrels']\n",
    "    \n",
    "    if total_queries > 0:\n",
    "        avg_ndcg = total_ndcg / total_queries\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìà AVERAGE NDCG@10: {avg_ndcg:.4f}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        baseline = 0.328\n",
    "        gain = avg_ndcg - baseline\n",
    "        gain_pct = (gain / baseline) * 100\n",
    "        \n",
    "        print(f\"\\nüéØ vs Baseline:\")\n",
    "        print(f\"   Baseline: {baseline:.4f}\")\n",
    "        print(f\"   Improved: {avg_ndcg:.4f}\")\n",
    "        print(f\"   Gain: +{gain:.4f} ({gain_pct:+.1f}%)\")\n",
    "        \n",
    "        if avg_ndcg >= 0.58:\n",
    "            print(f\"\\nüèÜ Likely TOP 3!\")\n",
    "        elif avg_ndcg >= 0.50:\n",
    "            print(f\"\\n‚úÖ Good progress, tune more!\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è Need more work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8876d85",
   "metadata": {},
   "source": [
    "## üíæ Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "348e21c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved: submission_improved.csv\n",
      "   Entries: 46710\n",
      "   Queries: 4671\n",
      "\n",
      "üìã Sample:\n",
      "    query_id  corpus_id\n",
      "0  qd4982518  dd4c4f7aa\n",
      "1  qd4982518  dd4bb016e\n",
      "2  qd4982518  dd4b9f7f6\n",
      "3  qd4982518  dd4bb5506\n",
      "4  qd4982518  dd4bbdb16\n",
      "5  qd4982518  dd4b87d18\n",
      "6  qd4982518  dd4be45d6\n",
      "7  qd4982518  dd4bd3790\n",
      "8  qd4982518  dd4c0119a\n",
      "9  qd4982518  dd4b89cbc\n",
      "\n",
      "üîç Validation:\n",
      "   Per query: {10: 4671}\n",
      "   ‚úÖ All queries have 10 results\n"
     ]
    }
   ],
   "source": [
    "if all_results:\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    submission_df = final_df[['query_id', 'corpus_id']]\n",
    "    \n",
    "    submission_df.to_csv(CONFIG['output_file'], index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Saved: {CONFIG['output_file']}\")\n",
    "    print(f\"   Entries: {len(submission_df)}\")\n",
    "    print(f\"   Queries: {submission_df['query_id'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nüìã Sample:\")\n",
    "    print(submission_df.head(10))\n",
    "    \n",
    "    counts = submission_df.groupby('query_id').size()\n",
    "    print(f\"\\nüîç Validation:\")\n",
    "    print(f\"   Per query: {counts.value_counts().to_dict()}\")\n",
    "    if (counts == 10).all():\n",
    "        print(f\"   ‚úÖ All queries have 10 results\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f666fc",
   "metadata": {},
   "source": [
    "## üéØ Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2051a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéâ IMPROVED PIPELINE COMPLETED!\n",
      "============================================================\n",
      "\n",
      "‚úÖ Improvements:\n",
      "   1. Table-aware chunking\n",
      "   2. BGE-reranker-v2-m3 (SOTA)\n",
      "   3. Hybrid retrieval (BM25+Dense)\n",
      "   4. Local evaluation\n",
      "   5. Optimized parameters\n",
      "\n",
      "üíæ Next: Submit to Kaggle!\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ IMPROVED PIPELINE COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚úÖ Improvements:\")\n",
    "print(\"   1. Table-aware chunking\")\n",
    "print(\"   2. BGE-reranker-v2-m3 (SOTA)\")\n",
    "print(\"   3. Hybrid retrieval (BM25+Dense)\")\n",
    "print(\"   4. Local evaluation\")\n",
    "print(\"   5. Optimized parameters\")\n",
    "\n",
    "print(\"\\nüíæ Next: Submit to Kaggle!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f566c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financerag_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
