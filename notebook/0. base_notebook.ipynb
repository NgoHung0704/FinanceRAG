{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b14555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  data_dir: ../data\n",
      "  output_file: submission.csv\n",
      "  embedding_model: BAAI/bge-m3\n",
      "  reranker_model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "  top_k_retrieval: 50\n",
      "  top_k_final: 10\n",
      "  embed_batch_size: 8\n",
      "  rerank_batch_size: 8\n",
      "  max_length: 4096\n",
      "  datasets: 7 datasets\n"
     ]
    }
   ],
   "source": [
    "# Pipeline Configuration\n",
    "CONFIG = {\n",
    "    # Paths\n",
    "    'data_dir': '../data',\n",
    "    'output_file': 'submission.csv',\n",
    "    \n",
    "    # Datasets to process (7 financial datasets)\n",
    "    'datasets': [\n",
    "        'convfinqa',\n",
    "        'financebench', \n",
    "        'finder',\n",
    "        'finqa',\n",
    "        'finqabench',\n",
    "        'multiheirtt',\n",
    "        'tatqa'\n",
    "    ],\n",
    "    \n",
    "    # Model names\n",
    "    'embedding_model': 'BAAI/bge-m3',  # Supports up to 8192 tokens, good for financial documents\n",
    "    'reranker_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2',  # Fast and effective\n",
    "    \n",
    "    # Retrieval parameters\n",
    "    'top_k_retrieval': 50,  # Retrieve top-50 candidates\n",
    "    'top_k_final': 10,       # Rerank to top-10 for submission\n",
    "    \n",
    "    # Batch sizes (reduced to prevent OOM)\n",
    "    'embed_batch_size': 8,   # Reduced from 32 - financial docs are very long\n",
    "    'rerank_batch_size': 8,  # Reduced from 16\n",
    "    \n",
    "    # Text length limit (to prevent OOM)\n",
    "    'max_length': 4096,      # Truncate very long documents (BGE-M3 supports 8192 but uses too much memory)\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    if key != 'datasets':\n",
    "        print(f\"  {key}: {value}\")\n",
    "print(f\"  datasets: {len(CONFIG['datasets'])} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d370e3",
   "metadata": {},
   "source": [
    "# FinanceRAG - Full Retrieval Pipeline\n",
    "\n",
    "**Objective:** Retrieve top 10 most relevant documents for each query across 7 financial datasets.\n",
    "\n",
    "**Strategy:** \n",
    "1. Process each dataset separately (Divide & Conquer)\n",
    "2. Use Bi-Encoder (BGE-M3) for fast retrieval (Top-50)\n",
    "3. Use Cross-Encoder (BGE-Reranker) for precise reranking (Top-10)\n",
    "4. Combine all results into submission file\n",
    "\n",
    "**No Generation needed** - Pure Retrieval Task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582e96b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\financerag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Embedding & Retrieval\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Reranking\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Utils\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971d3584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Running on CPU\n",
      "\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability and set device\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d60c9",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51db16",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b25ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_data(dataset_name: str, data_dir: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load corpus and queries for a given dataset.\n",
    "    \n",
    "    Note: In this project, corpus files are in subfolders:\n",
    "    e.g., data/financebench_corpus.jsonl/corpus.jsonl\n",
    "    \"\"\"\n",
    "    # Construct paths (corpus is in subfolder)\n",
    "    corpus_path = os.path.join(data_dir, f\"{dataset_name}_corpus.jsonl\", \"corpus.jsonl\")\n",
    "    queries_path = os.path.join(data_dir, f\"{dataset_name}_queries.jsonl\", \"queries.jsonl\")\n",
    "    \n",
    "    # Check if files exist\n",
    "    if not os.path.exists(corpus_path):\n",
    "        raise FileNotFoundError(f\"Corpus not found: {corpus_path}\")\n",
    "    if not os.path.exists(queries_path):\n",
    "        raise FileNotFoundError(f\"Queries not found: {queries_path}\")\n",
    "    \n",
    "    # Load data\n",
    "    corpus_df = pd.read_json(corpus_path, lines=True)\n",
    "    queries_df = pd.read_json(queries_path, lines=True)\n",
    "    \n",
    "    print(f\"  Loaded {len(corpus_df)} corpus documents, {len(queries_df)} queries\")\n",
    "    \n",
    "    return corpus_df, queries_df\n",
    "\n",
    "\n",
    "def prepare_texts(df: pd.DataFrame, combine_title: bool = True) -> List[str]:\n",
    "    \"\"\"\n",
    "    Prepare text from dataframe for embedding.\n",
    "    \n",
    "    For financial documents, combining title + text is crucial:\n",
    "    - Title often contains company name, year, report type\n",
    "    - Helps disambiguate between similar documents\n",
    "    \"\"\"\n",
    "    if combine_title and 'title' in df.columns:\n",
    "        # Combine title and text with proper formatting\n",
    "        texts = []\n",
    "        for _, row in df.iterrows():\n",
    "            title = str(row.get('title', '')).strip()\n",
    "            text = str(row.get('text', '')).strip()\n",
    "            if title and text:\n",
    "                combined = f\"{title}. {text}\" \n",
    "            elif title:\n",
    "                combined = title\n",
    "            else:\n",
    "                combined = text\n",
    "            texts.append(combined)\n",
    "        return texts\n",
    "    else:\n",
    "        return df['text'].astype(str).tolist()\n",
    "\n",
    "\n",
    "def build_faiss_index(embeddings: np.ndarray, use_gpu: bool = False) -> faiss.Index:\n",
    "    \"\"\"\n",
    "    Build FAISS index for fast similarity search.\n",
    "    \n",
    "    Using IndexFlatIP (Inner Product) because BGE models output normalized vectors.\n",
    "    \"\"\"\n",
    "    dimension = embeddings.shape[0]\n",
    "    \n",
    "    # Create index\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    \n",
    "    # Move to GPU if available and requested\n",
    "    if use_gpu and faiss.get_num_gpus() > 0:\n",
    "        print(\"  Using GPU for FAISS\")\n",
    "        res = faiss.StandardGpuResources()\n",
    "        index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9554b2c9",
   "metadata": {},
   "source": [
    "## Load Models (Once for All Datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4af8f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models... This may take a few minutes on first run.\n",
      "\n",
      "1. Loading embedding model: BAAI/bge-m3\n",
      "   Model loaded on cpu\n",
      "\n",
      "2. Loading reranker model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "   Reranker loaded on cpu\n",
      "\n",
      "‚úÖ All models loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading models... This may take a few minutes on first run.\")\n",
    "\n",
    "# 1. Bi-Encoder for Retrieval (Fast, captures semantic similarity)\n",
    "print(f\"\\n1. Loading embedding model: {CONFIG['embedding_model']}\")\n",
    "embed_model = SentenceTransformer(\n",
    "    CONFIG['embedding_model'], \n",
    "    device=device,\n",
    "    trust_remote_code=True  # Allow loading custom model architectures\n",
    ")\n",
    "print(f\"   Model loaded on {device}\")\n",
    "\n",
    "# 2. Cross-Encoder for Reranking (Slower but more accurate)\n",
    "print(f\"\\n2. Loading reranker model: {CONFIG['reranker_model']}\")\n",
    "reranker = CrossEncoder(\n",
    "    CONFIG['reranker_model'], \n",
    "    device=device, \n",
    "    max_length=512\n",
    ")\n",
    "print(f\"   Reranker loaded on {device}\")\n",
    "\n",
    "print(\"\\n‚úÖ All models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2e13f1",
   "metadata": {},
   "source": [
    "## Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e0bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_name: str, config: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Complete pipeline for one dataset:\n",
    "    1. Load data\n",
    "    2. Embed corpus\n",
    "    3. Build FAISS index\n",
    "    4. Retrieve top-K candidates\n",
    "    5. Rerank to top-10\n",
    "    6. Return results\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {dataset_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # --- STEP 1: Load Data ---\n",
    "    corpus_df, queries_df = load_jsonl_data(dataset_name, config['data_dir'])\n",
    "    \n",
    "    # Prepare texts for embedding\n",
    "    corpus_texts = prepare_texts(corpus_df, combine_title=True)\n",
    "    corpus_ids = corpus_df['_id'].tolist()\n",
    "    \n",
    "    query_texts = prepare_texts(queries_df, combine_title=False)  # Queries don't have titles\n",
    "    query_ids = queries_df['_id'].tolist()\n",
    "    \n",
    "    # --- STEP 2: Embed Corpus ---\n",
    "    print(f\"\\nüìä Embedding {len(corpus_texts)} documents...\")\n",
    "    max_length = config.get('max_length', 4096)\n",
    "    corpus_embeddings = embed_model.encode(\n",
    "        corpus_texts,\n",
    "        batch_size=config['embed_batch_size'],\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    \n",
    "    # --- STEP 3: Build FAISS Index ---\n",
    "    print(f\"\\nüîç Building FAISS index...\")\n",
    "    dimension = corpus_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    index.add(corpus_embeddings.astype('float32'))\n",
    "    print(f\"   Index built with {index.ntotal} vectors\")\n",
    "    \n",
    "    # Free memory\n",
    "    del corpus_embeddings\n",
    "    if device == 'cuda':\n",
    "        import torch\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # --- STEP 4: Retrieve Top-K Candidates ---\n",
    "    print(f\"\\nüéØ Retrieving top-{config['top_k_retrieval']} candidates for {len(query_texts)} queries...\")\n",
    "    query_embeddings = embed_model.encode(\n",
    "        query_texts,\n",
    "        batch_size=config['embed_batch_size'],\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    \n",
    "    # Search FAISS index\n",
    "    distances, indices = index.search(\n",
    "        query_embeddings.astype('float32'),\n",
    "        config['top_k_retrieval']\n",
    "    )\n",
    "    \n",
    "    # Free memory\n",
    "    del query_embeddings\n",
    "    if device == 'cuda':\n",
    "        import torch\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # --- STEP 5: Rerank to Top-10 ---\n",
    "    print(f\"\\n‚ö° Reranking to top-{config['top_k_final']}...\")\n",
    "    results = []\n",
    "    rerank_batch_size = config.get('rerank_batch_size', 8)\n",
    "    \n",
    "    for i, query_id in enumerate(tqdm(query_ids, desc=\"Reranking\")):\n",
    "        query_text = query_texts[i]\n",
    "        \n",
    "        # Get candidates from retrieval step\n",
    "        candidate_indices = indices[i]\n",
    "        candidate_texts = [corpus_texts[idx] for idx in candidate_indices]\n",
    "        candidate_ids = [corpus_ids[idx] for idx in candidate_indices]\n",
    "        \n",
    "        # Truncate candidate texts to prevent OOM in reranker\n",
    "        max_rerank_len = 512\n",
    "        candidate_texts = [text[:max_rerank_len*4] for text in candidate_texts]\n",
    "        \n",
    "        # Create pairs for reranker\n",
    "        pairs = [[query_text, doc_text] for doc_text in candidate_texts]\n",
    "        \n",
    "        # Get reranking scores\n",
    "        scores = reranker.predict(pairs, show_progress_bar=False, batch_size=rerank_batch_size)\n",
    "        \n",
    "        # Sort by score and take top-10\n",
    "        scored_candidates = list(zip(candidate_ids, scores))\n",
    "        scored_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_10 = scored_candidates[:config['top_k_final']]\n",
    "        \n",
    "        # Store results\n",
    "        for corpus_id, score in top_10:\n",
    "            results.append({\n",
    "                'query_id': query_id,\n",
    "                'corpus_id': corpus_id,\n",
    "                'score': float(score)\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(f\"\\n‚úÖ Completed {dataset_name}: {len(results_df)} results\")\n",
    "    \n",
    "    # Clear GPU cache\n",
    "    if device == 'cuda':\n",
    "        import torch\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"   GPU cache cleared\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5755da",
   "metadata": {},
   "source": [
    "## Run Pipeline for All Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8489c6a2",
   "metadata": {},
   "source": [
    "## Generate Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b03dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline for 7 datasets...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: CONVFINQA\n",
      "============================================================\n",
      "  Loaded 2066 corpus documents, 421 queries\n",
      "\n",
      "üìä Embedding 2066 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 259/259 [1:30:12<00:00, 20.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS index...\n",
      "   Index built with 2066 vectors\n",
      "\n",
      "üéØ Retrieving top-50 candidates for 421 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53/53 [00:22<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° Reranking to top-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 421/421 [18:58<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Completed convfinqa: 4210 results\n",
      "\n",
      "============================================================\n",
      "Processing: FINANCEBENCH\n",
      "============================================================\n",
      "  Loaded 180 corpus documents, 150 queries\n",
      "\n",
      "üìä Embedding 180 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [02:42<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS index...\n",
      "   Index built with 180 vectors\n",
      "\n",
      "üéØ Retrieving top-50 candidates for 150 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:16<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° Reranking to top-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [06:54<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Completed financebench: 1500 results\n",
      "\n",
      "============================================================\n",
      "Processing: FINDER\n",
      "============================================================\n",
      "  Loaded 13867 corpus documents, 216 queries\n",
      "\n",
      "üìä Embedding 13867 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1734/1734 [1:37:13<00:00,  3.36s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS index...\n",
      "   Index built with 13867 vectors\n",
      "\n",
      "üéØ Retrieving top-50 candidates for 216 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:09<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° Reranking to top-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 216/216 [07:01<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Completed finder: 2160 results\n",
      "\n",
      "============================================================\n",
      "Processing: FINQA\n",
      "============================================================\n",
      "  Loaded 2789 corpus documents, 1147 queries\n",
      "\n",
      "üìä Embedding 2789 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 349/349 [1:55:54<00:00, 19.93s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS index...\n",
      "   Index built with 2789 vectors\n",
      "\n",
      "üéØ Retrieving top-50 candidates for 1147 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 144/144 [01:11<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° Reranking to top-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1147/1147 [52:20<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Completed finqa: 11470 results\n",
      "\n",
      "============================================================\n",
      "Processing: FINQABENCH\n",
      "============================================================\n",
      "  Loaded 92 corpus documents, 100 queries\n",
      "\n",
      "üìä Embedding 92 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [01:48<00:00,  9.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS index...\n",
      "   Index built with 92 vectors\n",
      "\n",
      "üéØ Retrieving top-50 candidates for 100 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:07<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° Reranking to top-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [04:14<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Completed finqabench: 1000 results\n",
      "\n",
      "============================================================\n",
      "Processing: MULTIHEIRTT\n",
      "============================================================\n",
      "  Loaded 10475 corpus documents, 974 queries\n",
      "\n",
      "üìä Embedding 10475 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1310/1310 [7:31:57<00:00, 20.70s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS index...\n",
      "   Index built with 10475 vectors\n",
      "\n",
      "üéØ Retrieving top-50 candidates for 974 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122/122 [01:07<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° Reranking to top-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 974/974 [45:52<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Completed multiheirtt: 9740 results\n",
      "\n",
      "============================================================\n",
      "Processing: TATQA\n",
      "============================================================\n",
      "  Loaded 2756 corpus documents, 1663 queries\n",
      "\n",
      "üìä Embedding 2756 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 345/345 [57:11<00:00,  9.95s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Building FAISS index...\n",
      "   Index built with 2756 vectors\n",
      "\n",
      "üéØ Retrieving top-50 candidates for 1663 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 208/208 [01:27<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö° Reranking to top-10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1663/1663 [2:10:52<00:00,  4.72s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Completed tatqa: 16630 results\n",
      "\n",
      "============================================================\n",
      "Pipeline completed!\n",
      "  Successful: 7/7 datasets\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "failed_datasets = []\n",
    "\n",
    "print(f\"Starting pipeline for {len(CONFIG['datasets'])} datasets...\\n\")\n",
    "\n",
    "for dataset_name in CONFIG['datasets']:\n",
    "    try:\n",
    "        df_results = process_dataset(dataset_name, CONFIG)\n",
    "        all_results.append(df_results)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error processing {dataset_name}: {str(e)}\")\n",
    "        failed_datasets.append(dataset_name)\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Pipeline completed!\")\n",
    "print(f\"  Successful: {len(all_results)}/{len(CONFIG['datasets'])} datasets\")\n",
    "if failed_datasets:\n",
    "    print(f\"  Failed: {', '.join(failed_datasets)}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3fef1f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e9fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Submission file saved: submission.csv\n",
      "   Total entries: 46710\n",
      "   Unique queries: 4671\n",
      "   Expected format: query_id, corpus_id\n",
      "\n",
      "üìã First 10 rows:\n",
      "    query_id  corpus_id\n",
      "0  qd4982518  dd4bb5506\n",
      "1  qd4982518  dd4bb016e\n",
      "2  qd4982518  dd4b9f7f6\n",
      "3  qd4982518  dd4bf5c14\n",
      "4  qd4982518  dd4971510\n",
      "5  qd4982518  dd4be45d6\n",
      "6  qd4982518  dd4bf6f9c\n",
      "7  qd4982518  dd4c4f7aa\n",
      "8  qd4982518  dd4bf1060\n",
      "9  qd4982518  dd4b87d18\n",
      "\n",
      "üîç Validation:\n",
      "   - Each query should have 10 results: {10: 4671}\n",
      "   - No null values: True\n"
     ]
    }
   ],
   "source": [
    "# Combine all results\n",
    "if all_results:\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Submission format: query_id, corpus_id (no score column)\n",
    "    submission_df = final_df[['query_id', 'corpus_id']]\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = CONFIG['output_file']\n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Submission file saved: {output_path}\")\n",
    "    print(f\"   Total entries: {len(submission_df)}\")\n",
    "    print(f\"   Unique queries: {submission_df['query_id'].nunique()}\")\n",
    "    print(f\"   Expected format: query_id, corpus_id\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(f\"\\nüìã First 10 rows:\")\n",
    "    print(submission_df.head(10))\n",
    "    \n",
    "    # Validation checks\n",
    "    print(f\"\\nüîç Validation:\")\n",
    "    print(f\"   - Each query should have 10 results: {submission_df.groupby('query_id').size().value_counts().to_dict()}\")\n",
    "    print(f\"   - No null values: {submission_df.isnull().sum().sum() == 0}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No results to save. All datasets failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7bca33",
   "metadata": {},
   "source": [
    "## Statistics & Analysis (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d2b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Statistics by Dataset:\n",
      "============================================================\n",
      "\n",
      "CONVFINQA:\n",
      "  Queries: 421\n",
      "  Total results: 4210\n",
      "  Avg rerank score: 1.0205\n",
      "  Min/Max score: -10.9718 / 8.8219\n",
      "  ‚úÖ All queries have exactly 10 results\n",
      "\n",
      "FINANCEBENCH:\n",
      "  Queries: 150\n",
      "  Total results: 1500\n",
      "  Avg rerank score: -5.1912\n",
      "  Min/Max score: -11.2769 / 8.8339\n",
      "  ‚úÖ All queries have exactly 10 results\n",
      "\n",
      "FINDER:\n",
      "  Queries: 216\n",
      "  Total results: 2160\n",
      "  Avg rerank score: 0.8377\n",
      "  Min/Max score: -10.2328 / 10.2082\n",
      "  ‚úÖ All queries have exactly 10 results\n",
      "\n",
      "FINQA:\n",
      "  Queries: 1147\n",
      "  Total results: 11470\n",
      "  Avg rerank score: 1.0698\n",
      "  Min/Max score: -10.9311 / 9.1062\n",
      "  ‚úÖ All queries have exactly 10 results\n",
      "\n",
      "FINQABENCH:\n",
      "  Queries: 100\n",
      "  Total results: 1000\n",
      "  Avg rerank score: -0.9521\n",
      "  Min/Max score: -11.2623 / 10.8378\n",
      "  ‚úÖ All queries have exactly 10 results\n",
      "\n",
      "MULTIHEIRTT:\n",
      "  Queries: 974\n",
      "  Total results: 9740\n",
      "  Avg rerank score: 0.4115\n",
      "  Min/Max score: -11.2165 / 9.1521\n",
      "  ‚úÖ All queries have exactly 10 results\n",
      "\n",
      "TATQA:\n",
      "  Queries: 1663\n",
      "  Total results: 16630\n",
      "  Avg rerank score: 2.8081\n",
      "  Min/Max score: -11.3337 / 11.1717\n",
      "  ‚úÖ All queries have exactly 10 results\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Analyze results per dataset\n",
    "if all_results and 'score' in final_df.columns:\n",
    "    print(\"\\nüìä Statistics by Dataset:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Add dataset identifier (extract from query_id pattern)\n",
    "    # Query IDs typically start with dataset name prefix\n",
    "    \n",
    "    for i, df in enumerate(all_results):\n",
    "        dataset = CONFIG['datasets'][i] if i < len(CONFIG['datasets']) else f\"Dataset_{i}\"\n",
    "        print(f\"\\n{dataset.upper()}:\")\n",
    "        print(f\"  Queries: {df['query_id'].nunique()}\")\n",
    "        print(f\"  Total results: {len(df)}\")\n",
    "        print(f\"  Avg rerank score: {df['score'].mean():.4f}\")\n",
    "        print(f\"  Min/Max score: {df['score'].min():.4f} / {df['score'].max():.4f}\")\n",
    "        \n",
    "        # Check if all queries have exactly 10 results\n",
    "        counts = df.groupby('query_id').size()\n",
    "        if (counts == 10).all():\n",
    "            print(f\"  ‚úÖ All queries have exactly 10 results\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  Some queries don't have 10 results: {counts.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c4573",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Next Steps for Improvement\n",
    "\n",
    "Based on this baseline, you can improve performance by:\n",
    "\n",
    "### 1. **Model Selection**\n",
    "- Try `BAAI/bge-large-en-v1.5` for better quality (but slower)\n",
    "- Try `BAAI/bge-reranker-v2-m3` for better reranking (needs FlagEmbedding library)\n",
    "- Fine-tune models on financial domain data\n",
    "\n",
    "### 2. **Text Preprocessing**\n",
    "- Extract tables separately and format them better\n",
    "- Handle multi-modal content (text + tables)\n",
    "- Clean HTML artifacts, special characters\n",
    "\n",
    "### 3. **Chunking Strategy**\n",
    "- For long documents, split into chunks\n",
    "- Use sliding window with overlap\n",
    "- Aggregate scores from multiple chunks\n",
    "\n",
    "### 4. **Retrieval Tuning**\n",
    "- Adjust `top_k_retrieval` (try 100 instead of 50)\n",
    "- Use hybrid search (BM25 + Dense)\n",
    "- Add query expansion\n",
    "\n",
    "### 5. **Reranking Optimization**\n",
    "- Ensemble multiple rerankers\n",
    "- Use domain-specific reranker\n",
    "- Adjust reranking batch size for speed\n",
    "\n",
    "### 6. **Post-Processing**\n",
    "- Remove duplicate documents\n",
    "- Apply business rules (e.g., prefer recent documents)\n",
    "- Use metadata filtering\n",
    "\n",
    "### 7. **Evaluation**\n",
    "- Use qrels files to compute NDCG@10 locally\n",
    "- Analyze failure cases\n",
    "- Create validation split for tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financerag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
