{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e7840d",
   "metadata": {},
   "source": [
    "# üöÄ Improved Chunking Pipeline (v·ªõi Dataset-Specific Chunking)\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "Pipeline n√†y s·ª≠ d·ª•ng **dataset-specific chunking strategies** ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u t·ª´ **Notebook 2**:\n",
    "\n",
    "### üéØ Key Features:\n",
    "\n",
    "1. **Dataset-Specific Chunking** üîß\n",
    "   - M·ªói dataset s·ª≠ d·ª•ng chunking method **t·ªëi ∆∞u ri√™ng**\n",
    "   - D·ª±a tr√™n evaluation trong notebook 2\n",
    "   - T·ª± ƒë·ªông load pre-chunked corpus (nhanh h∆°n, consistent h∆°n)\n",
    "\n",
    "2. **Hybrid Retrieval** üîç\n",
    "   - Dense retrieval (BAAI/bge-large-en-v1.5)\n",
    "   - BM25 (lexical matching)\n",
    "   - Weighted combination\n",
    "\n",
    "3. **Advanced Reranking** üìä\n",
    "   - BAAI/bge-reranker-v2-m3\n",
    "   - Re-score top candidates\n",
    "\n",
    "4. **Smart Aggregation** üîó\n",
    "   - Chunk-level retrieval\n",
    "   - Document-level aggregation (max score)\n",
    "\n",
    "### üìÇ Pre-Chunked Data Source:\n",
    "\n",
    "```\n",
    "../data/chunked_corpus/\n",
    "‚îú‚îÄ‚îÄ convfinqa_corpus_chunked_optimal.jsonl      (recursive 1536/200)\n",
    "‚îú‚îÄ‚îÄ financebench_corpus_chunked_optimal.jsonl   (recursive 768/75)  \n",
    "‚îú‚îÄ‚îÄ finder_corpus_chunked_optimal.jsonl         (recursive 512/50)\n",
    "‚îú‚îÄ‚îÄ finqa_corpus_chunked_optimal.jsonl          (preserve_tables 2048/200)\n",
    "‚îú‚îÄ‚îÄ finqabench_corpus_chunked_optimal.jsonl     (recursive 512/50)\n",
    "‚îú‚îÄ‚îÄ multiheirtt_corpus_chunked_optimal.jsonl    (preserve_tables 3000/300)\n",
    "‚îú‚îÄ‚îÄ tatqa_corpus_chunked_optimal.jsonl          (no_chunking)\n",
    "‚îî‚îÄ‚îÄ best_chunking_config_per_dataset.json       (configs)\n",
    "```\n",
    "\n",
    "### ‚ö° Performance:\n",
    "\n",
    "- ‚úÖ **Faster**: No need to chunk on-the-fly\n",
    "- ‚úÖ **Consistent**: Same chunks for all runs\n",
    "- ‚úÖ **Optimized**: Each dataset uses its best strategy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7fa98",
   "metadata": {},
   "source": [
    "## üì¶ Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q sentence-transformers faiss-cpu FlagEmbedding rank-bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4686d6",
   "metadata": {},
   "source": [
    "## üìö Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca10ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "# Embedding & Retrieval\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Reranking\n",
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "# BM25\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Utils\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ea7bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32164154",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd461dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n",
      "\n",
      "üéØ CHUNKING STRATEGY:\n",
      "   ‚úÖ Using PRE-CHUNKED corpus from notebook 2\n",
      "   üìÇ Source: ../data/chunked_corpus\n",
      "   üìã Config: ../data/chunked_corpus/best_chunking_config_per_dataset.json\n",
      "   ‚ÑπÔ∏è Each dataset uses its OPTIMAL chunking method\n",
      "\n",
      "üîó Aggregation: max (chunks ‚Üí docs)\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    'data_dir': '../data',\n",
    "    'output_file': 'submission_optimal_chunking.csv',\n",
    "    \n",
    "    'datasets': [\n",
    "        'convfinqa', 'financebench', 'finder',\n",
    "        'finqa', 'finqabench', 'multiheirtt', 'tatqa'\n",
    "    ],\n",
    "    \n",
    "    # Models - SOTA\n",
    "    'embedding_model': 'BAAI/bge-large-en-v1.5',\n",
    "    'reranker_model': 'BAAI/bge-reranker-v2-m3',\n",
    "    \n",
    "    # Chunking - OPTIMAL (from notebook 2 evaluation)\n",
    "    'use_prechunked': True,  # Load pre-chunked data from notebook 2\n",
    "    'chunked_corpus_dir': '../data/chunked_corpus',  # Pre-chunked files location\n",
    "    'chunking_config_file': '../data/chunked_corpus/best_chunking_config_per_dataset.json',  # Dataset-specific configs\n",
    "    'use_chunking': True,\n",
    "    'chunking_method': 'fixed',  # Fallback if pre-chunked not available\n",
    "    'chunk_size': 512,  # characters\n",
    "    'chunk_overlap': 50,  # characters\n",
    "    'chunk_aggregation': 'max',  # max score aggregation\n",
    "    'preserve_tables': True,  # Keep tables intact\n",
    "    \n",
    "    # Hybrid Search\n",
    "    'use_hybrid': True,\n",
    "    'hybrid_alpha': 0.6,  # 60% dense, 40% BM25\n",
    "    \n",
    "    # Retrieval Parameters\n",
    "    'top_k_retrieval': 100,  # Initial retrieval\n",
    "    'top_k_rerank': 50,  # Send to reranker\n",
    "    'top_k_final': 10,  # Final results per query\n",
    "    \n",
    "    # Batch Sizes\n",
    "    'embed_batch_size': 16,\n",
    "    'rerank_batch_size': 16,\n",
    "    'max_length': 512,\n",
    "    \n",
    "    # Evaluation\n",
    "    'eval_on_qrels': True,\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(\"\\nüéØ CHUNKING STRATEGY:\")\n",
    "if CONFIG['use_prechunked']:\n",
    "    print(f\"   ‚úÖ Using PRE-CHUNKED corpus from notebook 2\")\n",
    "    print(f\"   üìÇ Source: {CONFIG['chunked_corpus_dir']}\")\n",
    "    print(f\"   üìã Config: {CONFIG['chunking_config_file']}\")\n",
    "    print(f\"   ‚ÑπÔ∏è Each dataset uses its OPTIMAL chunking method\")\n",
    "else:\n",
    "    print(f\"   Method: {CONFIG['chunking_method']}\")\n",
    "    print(f\"   Chunk Size: {CONFIG['chunk_size']} characters\")\n",
    "    print(f\"   Overlap: {CONFIG['chunk_overlap']} characters\")\n",
    "    print(f\"   Table Preservation: {CONFIG['preserve_tables']}\")\n",
    "print(f\"\\nüîó Aggregation: {CONFIG['chunk_aggregation']} (chunks ‚Üí docs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a585335",
   "metadata": {},
   "source": [
    "## üîß Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "793e79a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "def load_jsonl_data(dataset_name: str, data_dir: str):\n",
    "    \"\"\"Load corpus, queries, and qrels\"\"\"\n",
    "    corpus_path = os.path.join(data_dir, f\"{dataset_name}_corpus.jsonl\", \"corpus.jsonl\")\n",
    "    queries_path = os.path.join(data_dir, f\"{dataset_name}_queries.jsonl\", \"queries.jsonl\")\n",
    "    \n",
    "    # Map dataset names to qrels files\n",
    "    qrels_mapping = {\n",
    "        'convfinqa': 'ConvFinQA_qrels.tsv',\n",
    "        'financebench': 'FinanceBench_qrels.tsv',\n",
    "        'finder': 'FinDER_qrels.tsv',\n",
    "        'finqa': 'FinQA_qrels.tsv',\n",
    "        'finqabench': 'FinQABench_qrels.tsv',\n",
    "        'multiheirtt': 'MultiHeirtt_qrels.tsv',\n",
    "        'tatqa': 'TATQA_qrels.tsv'\n",
    "    }\n",
    "    \n",
    "    qrels_path = os.path.join(data_dir, qrels_mapping.get(dataset_name, f\"{dataset_name}_qrels.tsv\"))\n",
    "    \n",
    "    corpus_df = pd.read_json(corpus_path, lines=True)\n",
    "    queries_df = pd.read_json(queries_path, lines=True)\n",
    "    \n",
    "    qrels_df = None\n",
    "    if os.path.exists(qrels_path):\n",
    "        qrels_df = pd.read_csv(qrels_path, sep='\\t')\n",
    "    \n",
    "    print(f\"  Loaded {len(corpus_df)} docs, {len(queries_df)} queries\")\n",
    "    return corpus_df, queries_df, qrels_df\n",
    "\n",
    "\n",
    "def load_prechunked_corpus(dataset_name: str, chunked_dir: str, config_file: str = None):\n",
    "    \"\"\"Load pre-chunked corpus from notebook 2 evaluation\"\"\"\n",
    "    import json\n",
    "    \n",
    "    chunked_path = os.path.join(chunked_dir, f\"{dataset_name}_corpus_chunked_optimal.jsonl\")\n",
    "    \n",
    "    if not os.path.exists(chunked_path):\n",
    "        print(f\"  ‚ö†Ô∏è Pre-chunked file not found: {chunked_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Load chunking config to show which method was used\n",
    "    chunking_method = \"unknown\"\n",
    "    if config_file and os.path.exists(config_file):\n",
    "        with open(config_file, 'r') as f:\n",
    "            configs = json.load(f)\n",
    "            if dataset_name in configs:\n",
    "                cfg = configs[dataset_name]\n",
    "                method = cfg.get('method', 'unknown')\n",
    "                if method != 'no_chunking' and cfg.get('chunk_size'):\n",
    "                    chunking_method = f\"{method} ({cfg['chunk_size']}/{cfg['chunk_overlap']})\"\n",
    "                else:\n",
    "                    chunking_method = method\n",
    "    \n",
    "    # Load pre-chunked corpus\n",
    "    chunks = []\n",
    "    with open(chunked_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            chunks.append(json.loads(line))\n",
    "    \n",
    "    print(f\"  ‚úÖ Loaded {len(chunks)} pre-chunked chunks\")\n",
    "    print(f\"  üìã Method used: {chunking_method}\")\n",
    "    return chunks, chunking_method\n",
    "\n",
    "\n",
    "print(\"‚úÖ Data loading functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de87a3",
   "metadata": {},
   "source": [
    "## ‚úÖ Verify Pre-Chunked Data\n",
    "\n",
    "Before running the pipeline, let's verify that pre-chunked data from notebook 2 is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95af5e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üîç VERIFICATION: Pre-Chunked Data from Notebook 2\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Config file found: ../data/chunked_corpus/best_chunking_config_per_dataset.json\n",
      "\n",
      "üìã Dataset-Specific Chunking Configurations:\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset         Method                    NDCG@10      Status    \n",
      "--------------------------------------------------------------------------------\n",
      "convfinqa       recursive (1536/200)      0.6081       ‚úÖ Ready   \n",
      "financebench    recursive (768/75)        1.0330       ‚úÖ Ready   \n",
      "finder          recursive (512/50)        0.5777       ‚úÖ Ready   \n",
      "finqa           preserve_tables (2048/200) 0.5591       ‚úÖ Ready   \n",
      "finqabench      recursive (512/50)        1.3488       ‚úÖ Ready   \n",
      "multiheirtt     preserve_tables (3000/300) 0.1948       ‚úÖ Ready   \n",
      "tatqa           no_chunking               0.3408       ‚úÖ Ready   \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Summary: 7/7 datasets have pre-chunked corpus\n",
      "‚úÖ All datasets ready! Pipeline will use pre-chunked data.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Check pre-chunked files\n",
    "chunked_dir = CONFIG['chunked_corpus_dir']\n",
    "config_file = CONFIG['chunking_config_file']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üîç VERIFICATION: Pre-Chunked Data from Notebook 2\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check if config file exists\n",
    "if os.path.exists(config_file):\n",
    "    print(f\"\\n‚úÖ Config file found: {config_file}\")\n",
    "    \n",
    "    with open(config_file, 'r') as f:\n",
    "        chunk_configs = json.load(f)\n",
    "    \n",
    "    print(f\"\\nüìã Dataset-Specific Chunking Configurations:\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"{'Dataset':<15} {'Method':<25} {'NDCG@10':<12} {'Status':<10}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for dataset in CONFIG['datasets']:\n",
    "        if dataset in chunk_configs:\n",
    "            cfg = chunk_configs[dataset]\n",
    "            method = cfg['method']\n",
    "            \n",
    "            # Format method string\n",
    "            if method != 'no_chunking' and cfg.get('chunk_size'):\n",
    "                method_str = f\"{method} ({cfg['chunk_size']}/{cfg['chunk_overlap']})\"\n",
    "            else:\n",
    "                method_str = method\n",
    "            \n",
    "            ndcg = cfg.get('ndcg_10', 0.0)\n",
    "            \n",
    "            # Check if chunked file exists\n",
    "            chunked_file = os.path.join(chunked_dir, f\"{dataset}_corpus_chunked_optimal.jsonl\")\n",
    "            status = \"‚úÖ Ready\" if os.path.exists(chunked_file) else \"‚ùå Missing\"\n",
    "            \n",
    "            print(f\"{dataset:<15} {method_str:<25} {ndcg:<12.4f} {status:<10}\")\n",
    "        else:\n",
    "            print(f\"{dataset:<15} {'N/A':<25} {'N/A':<12} {'‚ùå Missing':<10}\")\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Count available files\n",
    "    available = sum(1 for d in CONFIG['datasets'] \n",
    "                   if os.path.exists(os.path.join(chunked_dir, f\"{d}_corpus_chunked_optimal.jsonl\")))\n",
    "    print(f\"\\nüìä Summary: {available}/{len(CONFIG['datasets'])} datasets have pre-chunked corpus\")\n",
    "    \n",
    "    if available == len(CONFIG['datasets']):\n",
    "        print(\"‚úÖ All datasets ready! Pipeline will use pre-chunked data.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Some datasets missing. Pipeline will chunk on-the-fly for missing datasets.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Config file not found: {config_file}\")\n",
    "    print(\"‚ö†Ô∏è Pipeline will use fallback chunking settings.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60de00ca",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Optimal Chunking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae255373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Optimal chunking functions defined\n"
     ]
    }
   ],
   "source": [
    "def detect_tables(text: str) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Detect table regions using heuristics\"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    table_regions = []\n",
    "    in_table = False\n",
    "    table_start = 0\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        # Detect table markers: pipes, tabs, or multiple spaces\n",
    "        is_table = (\n",
    "            line.count('|') >= 2 or\n",
    "            line.count('\\t') >= 2 or\n",
    "            len(re.findall(r'\\s{3,}', line)) >= 2\n",
    "        )\n",
    "        \n",
    "        if is_table and not in_table:\n",
    "            in_table = True\n",
    "            table_start = max(0, i - 1)  # Include line before\n",
    "        elif not is_table and in_table:\n",
    "            in_table = False\n",
    "            table_end = min(len(lines), i + 1)  # Include line after\n",
    "            if table_end - table_start >= 3:  # At least 3 lines\n",
    "                table_regions.append((table_start, table_end))\n",
    "    \n",
    "    if in_table:\n",
    "        table_regions.append((table_start, len(lines)))\n",
    "    \n",
    "    return table_regions\n",
    "\n",
    "\n",
    "def chunk_text_fixed(text: str, chunk_size: int, overlap: int) -> List[str]:\n",
    "    \"\"\"Fixed-size character chunking with overlap\"\"\"\n",
    "    if len(text) <= chunk_size:\n",
    "        return [text]\n",
    "    \n",
    "    chunks = []\n",
    "    step = chunk_size - overlap\n",
    "    \n",
    "    for i in range(0, len(text), step):\n",
    "        chunk = text[i:i + chunk_size]\n",
    "        if len(chunk.strip()) >= 100:  # Minimum chunk size\n",
    "            chunks.append(chunk.strip())\n",
    "        \n",
    "        # Stop if we've reached the end\n",
    "        if i + chunk_size >= len(text):\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def chunk_document_optimal(doc_id: str, title: str, text: str, \n",
    "                          chunk_size: int, overlap: int, preserve_tables: bool):\n",
    "    \"\"\"Optimal chunking: fixed-size with table preservation\"\"\"\n",
    "    chunks = []\n",
    "    full_text = f\"{title}\\n{text}\" if title else text\n",
    "    \n",
    "    # For short documents, no chunking needed\n",
    "    if len(full_text) < chunk_size * 1.5:\n",
    "        chunks.append({\n",
    "            'chunk_id': f\"{doc_id}_c0\",\n",
    "            'text': full_text,\n",
    "            'doc_id': doc_id,\n",
    "            'is_table': False\n",
    "        })\n",
    "        return chunks\n",
    "    \n",
    "    # Detect tables\n",
    "    if preserve_tables:\n",
    "        lines = full_text.split('\\n')\n",
    "        table_regions = detect_tables(full_text)\n",
    "        \n",
    "        if table_regions:\n",
    "            chunk_idx = 0\n",
    "            prev_end = 0\n",
    "            \n",
    "            for table_start, table_end in table_regions:\n",
    "                # Chunk text before table\n",
    "                if table_start > prev_end:\n",
    "                    before_text = '\\n'.join(lines[prev_end:table_start])\n",
    "                    if before_text.strip():\n",
    "                        for chunk_text in chunk_text_fixed(before_text, chunk_size, overlap):\n",
    "                            chunks.append({\n",
    "                                'chunk_id': f\"{doc_id}_c{chunk_idx}\",\n",
    "                                'text': chunk_text,\n",
    "                                'doc_id': doc_id,\n",
    "                                'is_table': False\n",
    "                            })\n",
    "                            chunk_idx += 1\n",
    "                \n",
    "                # Keep table as single chunk\n",
    "                table_text = '\\n'.join(lines[table_start:table_end])\n",
    "                chunks.append({\n",
    "                    'chunk_id': f\"{doc_id}_t{chunk_idx}\",\n",
    "                    'text': f\"[TABLE]\\n{table_text}\",\n",
    "                    'doc_id': doc_id,\n",
    "                    'is_table': True\n",
    "                })\n",
    "                chunk_idx += 1\n",
    "                prev_end = table_end\n",
    "            \n",
    "            # Chunk text after last table\n",
    "            if prev_end < len(lines):\n",
    "                after_text = '\\n'.join(lines[prev_end:])\n",
    "                if after_text.strip():\n",
    "                    for chunk_text in chunk_text_fixed(after_text, chunk_size, overlap):\n",
    "                        chunks.append({\n",
    "                            'chunk_id': f\"{doc_id}_c{chunk_idx}\",\n",
    "                            'text': chunk_text,\n",
    "                            'doc_id': doc_id,\n",
    "                            'is_table': False\n",
    "                        })\n",
    "                        chunk_idx += 1\n",
    "            \n",
    "            return chunks\n",
    "    \n",
    "    # No tables detected or preservation disabled - simple fixed chunking\n",
    "    for i, chunk_text in enumerate(chunk_text_fixed(full_text, chunk_size, overlap)):\n",
    "        chunks.append({\n",
    "            'chunk_id': f\"{doc_id}_c{i}\",\n",
    "            'text': chunk_text,\n",
    "            'doc_id': doc_id,\n",
    "            'is_table': False\n",
    "        })\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "print(\"‚úÖ Optimal chunking functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016652e",
   "metadata": {},
   "source": [
    "## üîç Retrieval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce29e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieval functions defined\n"
     ]
    }
   ],
   "source": [
    "def normalize_scores(scores: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize scores to [0, 1]\"\"\"\n",
    "    if scores.max() == scores.min():\n",
    "        return np.ones_like(scores)\n",
    "    return (scores - scores.min()) / (scores.max() - scores.min())\n",
    "\n",
    "\n",
    "def hybrid_search(query_emb, query_text, faiss_index, bm25, corpus_texts, top_k, alpha=0.6):\n",
    "    \"\"\"Hybrid search: Dense + BM25\"\"\"\n",
    "    # Dense retrieval\n",
    "    dense_scores, indices = faiss_index.search(\n",
    "        query_emb.reshape(1, -1).astype('float32'), top_k * 2\n",
    "    )\n",
    "    dense_scores = dense_scores[0]\n",
    "    indices = indices[0]\n",
    "    \n",
    "    # BM25 retrieval\n",
    "    query_tokens = query_text.lower().split()\n",
    "    bm25_scores = bm25.get_scores(query_tokens)\n",
    "    bm25_subset = bm25_scores[indices]\n",
    "    \n",
    "    # Normalize both\n",
    "    dense_norm = normalize_scores(dense_scores)\n",
    "    bm25_norm = normalize_scores(bm25_subset)\n",
    "    \n",
    "    # Combine with alpha weighting\n",
    "    hybrid = alpha * dense_norm + (1 - alpha) * bm25_norm\n",
    "    \n",
    "    # Re-sort by hybrid scores\n",
    "    sorted_idx = np.argsort(hybrid)[::-1][:top_k]\n",
    "    return hybrid[sorted_idx], indices[sorted_idx]\n",
    "\n",
    "\n",
    "def aggregate_chunk_scores(chunk_scores: Dict, method='max') -> Dict:\n",
    "    \"\"\"Aggregate chunk scores to document scores\"\"\"\n",
    "    aggregated = {}\n",
    "    for doc_id, scores in chunk_scores.items():\n",
    "        if method == 'max':\n",
    "            aggregated[doc_id] = max(scores)\n",
    "        elif method == 'mean':\n",
    "            aggregated[doc_id] = np.mean(scores)\n",
    "        elif method == 'weighted':\n",
    "            # Weighted by position (higher weight for top chunks)\n",
    "            weights = np.array([1.0 / (i + 1) for i in range(len(scores))])\n",
    "            weights = weights / weights.sum()\n",
    "            aggregated[doc_id] = np.dot(scores, weights)\n",
    "        else:\n",
    "            aggregated[doc_id] = max(scores)\n",
    "    return aggregated\n",
    "\n",
    "\n",
    "print(\"‚úÖ Retrieval functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb98037",
   "metadata": {},
   "source": [
    "## üìä Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ac61a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def compute_ndcg(qrels: Dict, results: Dict, k=10) -> float:\n",
    "    \"\"\"Compute NDCG@k\"\"\"\n",
    "    ndcg_scores = []\n",
    "    for query_id, retrieved in results.items():\n",
    "        if query_id not in qrels:\n",
    "            continue\n",
    "        \n",
    "        relevant = qrels[query_id]\n",
    "        retrieved_k = retrieved[:k]\n",
    "        \n",
    "        # DCG\n",
    "        dcg = sum(relevant.get(doc_id, 0) / np.log2(i + 2) \n",
    "                  for i, doc_id in enumerate(retrieved_k))\n",
    "        \n",
    "        # IDCG\n",
    "        ideal = sorted(relevant.values(), reverse=True)[:k]\n",
    "        idcg = sum(rel / np.log2(i + 2) for i, rel in enumerate(ideal))\n",
    "        \n",
    "        if idcg > 0:\n",
    "            ndcg_scores.append(dcg / idcg)\n",
    "    \n",
    "    return np.mean(ndcg_scores) if ndcg_scores else 0.0\n",
    "\n",
    "\n",
    "def evaluate_results(results_df, qrels_df, k=10):\n",
    "    \"\"\"Evaluate results with qrels\"\"\"\n",
    "    # Handle both column naming conventions\n",
    "    query_col = 'query_id' if 'query_id' in qrels_df.columns else 'query-id'\n",
    "    corpus_col = 'corpus_id' if 'corpus_id' in qrels_df.columns else 'corpus-id'\n",
    "    \n",
    "    qrels = qrels_df.groupby(query_col).apply(\n",
    "        lambda x: dict(zip(x[corpus_col], x['score']))\n",
    "    ).to_dict()\n",
    "    \n",
    "    results = results_df.groupby('query_id')['corpus_id'].apply(list).to_dict()\n",
    "    \n",
    "    ndcg = compute_ndcg(qrels, results, k)\n",
    "    return {'NDCG@10': ndcg, 'num_queries': len(results), 'num_qrels': len(qrels)}\n",
    "\n",
    "\n",
    "print(\"‚úÖ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2d01b",
   "metadata": {},
   "source": [
    "## ü§ñ Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dec8bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "\n",
      "1. Loading embedding model: BAAI/bge-large-en-v1.5\n",
      "   ‚úÖ Done\n",
      "\n",
      "2. Loading reranker: BAAI/bge-reranker-v2-m3\n",
      "   ‚úÖ Done\n",
      "\n",
      "‚úÖ All models loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading models...\")\n",
    "\n",
    "# Embedding model\n",
    "print(f\"\\n1. Loading embedding model: {CONFIG['embedding_model']}\")\n",
    "embed_model = SentenceTransformer(CONFIG['embedding_model'], device=device)\n",
    "print(\"   ‚úÖ Done\")\n",
    "\n",
    "# Reranker model\n",
    "print(f\"\\n2. Loading reranker: {CONFIG['reranker_model']}\")\n",
    "reranker = FlagReranker(CONFIG['reranker_model'], use_fp16=(device=='cuda'))\n",
    "print(\"   ‚úÖ Done\")\n",
    "\n",
    "print(\"\\n‚úÖ All models loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bbb0a",
   "metadata": {},
   "source": [
    "## üîÑ Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6327c984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline function defined\n"
     ]
    }
   ],
   "source": [
    "def process_dataset_with_optimal_chunking(dataset_name: str, config: Dict):\n",
    "    \"\"\"Process dataset with optimal chunking strategy\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìä Processing: {dataset_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Load data\n",
    "    corpus_df, queries_df, qrels_df = load_jsonl_data(dataset_name, config['data_dir'])\n",
    "    \n",
    "    # Step 1: Load or Create Chunks\n",
    "    all_chunks = []\n",
    "    chunk_to_doc = {}\n",
    "    \n",
    "    # Try to load pre-chunked data first (from notebook 2)\n",
    "    chunking_method_used = None\n",
    "    if config.get('use_prechunked', False):\n",
    "        print(f\"\\nüìÇ Loading pre-chunked corpus from notebook 2...\")\n",
    "        print(f\"   Source: {config['chunked_corpus_dir']}\")\n",
    "        \n",
    "        all_chunks, chunking_method_used = load_prechunked_corpus(\n",
    "            dataset_name, \n",
    "            config['chunked_corpus_dir'],\n",
    "            config.get('chunking_config_file')\n",
    "        )\n",
    "        \n",
    "        if all_chunks:\n",
    "            # Build chunk-to-doc mapping (pre-chunked format uses 'original_id')\n",
    "            for c in all_chunks:\n",
    "                chunk_id = c.get('_id', c.get('chunk_id', ''))\n",
    "                doc_id = c.get('original_id', c.get('doc_id', chunk_id))\n",
    "                chunk_to_doc[chunk_id] = doc_id\n",
    "            \n",
    "            expansion_ratio = len(all_chunks) / len(corpus_df)\n",
    "            print(f\"   üìà Expansion: {len(corpus_df)} docs ‚Üí {len(all_chunks)} chunks ({expansion_ratio:.2f}x)\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è Pre-chunked data not found, will chunk on-the-fly\")\n",
    "            config['use_prechunked'] = False\n",
    "    \n",
    "    # Fallback: chunk on-the-fly if pre-chunked not available\n",
    "    if not config.get('use_prechunked', False) or not all_chunks:\n",
    "        print(f\"\\n‚úÇÔ∏è Chunking corpus on-the-fly...\")\n",
    "        print(f\"   Method: {config['chunking_method']}\")\n",
    "        print(f\"   Size: {config['chunk_size']} chars, Overlap: {config['chunk_overlap']} chars\")\n",
    "        \n",
    "        if config['use_chunking']:\n",
    "            for _, row in tqdm(corpus_df.iterrows(), total=len(corpus_df), desc=\"Chunking\"):\n",
    "                chunks = chunk_document_optimal(\n",
    "                    row['_id'], \n",
    "                    str(row.get('title', '')), \n",
    "                    str(row.get('text', '')),\n",
    "                    config['chunk_size'], \n",
    "                    config['chunk_overlap'], \n",
    "                    config['preserve_tables']\n",
    "                )\n",
    "                for c in chunks:\n",
    "                    all_chunks.append(c)\n",
    "                    chunk_to_doc[c['chunk_id']] = c['doc_id']\n",
    "            \n",
    "            num_tables = sum(1 for c in all_chunks if c.get('is_table', False))\n",
    "            expansion_ratio = len(all_chunks) / len(corpus_df)\n",
    "            print(f\"   ‚úÖ Created {len(all_chunks)} chunks from {len(corpus_df)} docs\")\n",
    "            print(f\"   üìà Expansion: {expansion_ratio:.2f}x\")\n",
    "            print(f\"   üìä Tables preserved: {num_tables}\")\n",
    "        else:\n",
    "            for _, row in corpus_df.iterrows():\n",
    "                doc_id = row['_id']\n",
    "                text = f\"[{row.get('title', '')}] {row.get('text', '')}\"\n",
    "                all_chunks.append({'chunk_id': doc_id, 'text': text, 'doc_id': doc_id})\n",
    "                chunk_to_doc[doc_id] = doc_id\n",
    "    \n",
    "    # Extract texts and IDs (handle both formats)\n",
    "    chunk_texts = [c.get('text', '') for c in all_chunks]\n",
    "    chunk_ids = [c.get('_id', c.get('chunk_id', '')) for c in all_chunks]\n",
    "    \n",
    "    # Ensure chunk_to_doc mapping is complete\n",
    "    if not chunk_to_doc:\n",
    "        for c in all_chunks:\n",
    "            cid = c.get('_id', c.get('chunk_id', ''))\n",
    "            did = c.get('original_id', c.get('doc_id', cid))\n",
    "            chunk_to_doc[cid] = did\n",
    "    \n",
    "    # Step 2: Embedding\n",
    "    print(f\"\\nüî¢ Encoding chunks...\")\n",
    "    chunk_embeddings = embed_model.encode(\n",
    "        chunk_texts, \n",
    "        batch_size=config['embed_batch_size'],\n",
    "        show_progress_bar=True, \n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    print(f\"   ‚úÖ Encoded {len(chunk_embeddings)} chunks\")\n",
    "    \n",
    "    # Step 3: Build FAISS Index\n",
    "    print(f\"\\nüîç Building FAISS index...\")\n",
    "    index = faiss.IndexFlatIP(chunk_embeddings.shape[1])\n",
    "    index.add(chunk_embeddings.astype('float32'))\n",
    "    print(f\"   ‚úÖ Index built with {index.ntotal} vectors\")\n",
    "    \n",
    "    # Step 4: Build BM25 Index (for hybrid)\n",
    "    bm25 = None\n",
    "    if config['use_hybrid']:\n",
    "        print(f\"\\nüî§ Building BM25 index...\")\n",
    "        tokenized = [t.lower().split() for t in chunk_texts]\n",
    "        bm25 = BM25Okapi(tokenized)\n",
    "        print(f\"   ‚úÖ BM25 index built\")\n",
    "    \n",
    "    # Free memory\n",
    "    del chunk_embeddings\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Step 5: Process Queries\n",
    "    print(f\"\\nüéØ Processing queries...\")\n",
    "    query_texts = [str(r.get('text', '')) for _, r in queries_df.iterrows()]\n",
    "    query_ids = queries_df['_id'].tolist()\n",
    "    \n",
    "    query_embeddings = embed_model.encode(\n",
    "        query_texts, \n",
    "        batch_size=config['embed_batch_size'],\n",
    "        show_progress_bar=True, \n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    print(f\"   ‚úÖ Encoded {len(query_embeddings)} queries\")\n",
    "    \n",
    "    # Step 6: Retrieve & Rerank\n",
    "    print(f\"\\nüîé Retrieving and reranking...\")\n",
    "    results = []\n",
    "    \n",
    "    for i, query_id in enumerate(tqdm(query_ids, desc=\"Retrieve+Rerank\")):\n",
    "        query_emb = query_embeddings[i]\n",
    "        query_text = query_texts[i]\n",
    "        \n",
    "        # Hybrid or dense retrieval\n",
    "        if config['use_hybrid'] and bm25:\n",
    "            scores, chunk_indices = hybrid_search(\n",
    "                query_emb, query_text, index, bm25, chunk_texts,\n",
    "                config['top_k_retrieval'], config['hybrid_alpha']\n",
    "            )\n",
    "        else:\n",
    "            scores, chunk_indices = index.search(\n",
    "                query_emb.reshape(1, -1).astype('float32'),\n",
    "                config['top_k_retrieval']\n",
    "            )\n",
    "            scores, chunk_indices = scores[0], chunk_indices[0]\n",
    "        \n",
    "        # Aggregate chunks to documents\n",
    "        doc_scores = {}\n",
    "        for idx, score in zip(chunk_indices, scores):\n",
    "            doc_id = chunk_to_doc[chunk_ids[idx]]\n",
    "            if doc_id not in doc_scores:\n",
    "                doc_scores[doc_id] = []\n",
    "            doc_scores[doc_id].append(float(score))\n",
    "        \n",
    "        doc_agg = aggregate_chunk_scores(doc_scores, config['chunk_aggregation'])\n",
    "        sorted_docs = sorted(doc_agg.items(), key=lambda x: x[1], reverse=True)[:config['top_k_rerank']]\n",
    "        \n",
    "        # Rerank top documents\n",
    "        candidate_ids = [d[0] for d in sorted_docs]\n",
    "        candidate_texts = [\n",
    "            str(corpus_df[corpus_df['_id']==d]['text'].values[0])[:2048]\n",
    "            for d in candidate_ids\n",
    "        ]\n",
    "        \n",
    "        pairs = [[query_text, t] for t in candidate_texts]\n",
    "        rerank_scores = reranker.compute_score(pairs)\n",
    "        \n",
    "        if not isinstance(rerank_scores, list):\n",
    "            rerank_scores = [rerank_scores]\n",
    "        \n",
    "        scored = list(zip(candidate_ids, rerank_scores))\n",
    "        scored.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Store top-k final results\n",
    "        for doc_id, score in scored[:config['top_k_final']]:\n",
    "            results.append({\n",
    "                'query_id': query_id,\n",
    "                'corpus_id': doc_id,\n",
    "                'score': float(score)\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(f\"   ‚úÖ Generated {len(results_df)} results\")\n",
    "    \n",
    "    # Step 7: Evaluate\n",
    "    eval_metrics = {}\n",
    "    if config['eval_on_qrels'] and qrels_df is not None:\n",
    "        print(f\"\\nüìä Evaluating...\")\n",
    "        eval_metrics = evaluate_results(results_df, qrels_df)\n",
    "        print(f\"   NDCG@10: {eval_metrics['NDCG@10']:.4f}\")\n",
    "        print(f\"   Queries evaluated: {eval_metrics['num_queries']}\")\n",
    "    \n",
    "    # Clean up\n",
    "    del query_embeddings, index\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return results_df, eval_metrics\n",
    "\n",
    "\n",
    "print(\"‚úÖ Pipeline function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdbf271",
   "metadata": {},
   "source": [
    "## üöÄ Run Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e6d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ STARTING OPTIMAL CHUNKING PIPELINE\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üìä Processing: CONVFINQA\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 2066 docs, 421 queries\n",
      "\n",
      "üìÇ Loading pre-chunked corpus from notebook 2...\n",
      "   Source: ../data/chunked_corpus\n",
      "  ‚úÖ Loaded 8667 pre-chunked chunks\n",
      "  üìã Method used: recursive (1536/200)\n",
      "   üìà Expansion: 2066 docs ‚Üí 8667 chunks (4.20x)\n",
      "\n",
      "üî¢ Encoding chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6606c730c6c0401aa67ebc403ec714e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 8667 chunks\n",
      "\n",
      "üîç Building FAISS index...\n",
      "   ‚úÖ Index built with 8667 vectors\n",
      "\n",
      "üî§ Building BM25 index...\n",
      "   ‚úÖ BM25 index built\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876a3137ffce409e9fbf0b31a872f211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 421 queries\n",
      "\n",
      "üîé Retrieving and reranking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ad4f345bc343898cd531cf0cd8e981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieve+Rerank:   0%|          | 0/421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Generated 4210 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.5068\n",
      "   Queries evaluated: 421\n",
      "\n",
      "======================================================================\n",
      "üìä Processing: FINANCEBENCH\n",
      "======================================================================\n",
      "  Loaded 180 docs, 150 queries\n",
      "\n",
      "üìÇ Loading pre-chunked corpus from notebook 2...\n",
      "   Source: ../data/chunked_corpus\n",
      "  ‚úÖ Loaded 539 pre-chunked chunks\n",
      "  üìã Method used: recursive (768/75)\n",
      "   üìà Expansion: 180 docs ‚Üí 539 chunks (2.99x)\n",
      "\n",
      "üî¢ Encoding chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af015ff2d3064af8809f542a999119ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 539 chunks\n",
      "\n",
      "üîç Building FAISS index...\n",
      "   ‚úÖ Index built with 539 vectors\n",
      "\n",
      "üî§ Building BM25 index...\n",
      "   ‚úÖ BM25 index built\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b5ef50ea4d456184f9f440f9e55c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 150 queries\n",
      "\n",
      "üîé Retrieving and reranking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4692a49caf441668fd277d471e4697c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieve+Rerank:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Generated 1500 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.7429\n",
      "   Queries evaluated: 150\n",
      "\n",
      "======================================================================\n",
      "üìä Processing: FINDER\n",
      "======================================================================\n",
      "  Loaded 13867 docs, 216 queries\n",
      "\n",
      "üìÇ Loading pre-chunked corpus from notebook 2...\n",
      "   Source: ../data/chunked_corpus\n",
      "  ‚úÖ Loaded 30511 pre-chunked chunks\n",
      "  üìã Method used: recursive (512/50)\n",
      "   üìà Expansion: 13867 docs ‚Üí 30511 chunks (2.20x)\n",
      "\n",
      "üî¢ Encoding chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cbeb57ae8f46aea3ea4a1cf07fdfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 30511 chunks\n",
      "\n",
      "üîç Building FAISS index...\n",
      "   ‚úÖ Index built with 30511 vectors\n",
      "\n",
      "üî§ Building BM25 index...\n",
      "   ‚úÖ BM25 index built\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebdf3a0913244739e1c0d62609f0d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 216 queries\n",
      "\n",
      "üîé Retrieving and reranking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c61815b559f407887bc9e9f31c544e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieve+Rerank:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Generated 2160 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.3903\n",
      "   Queries evaluated: 216\n",
      "\n",
      "======================================================================\n",
      "üìä Processing: FINQA\n",
      "======================================================================\n",
      "  Loaded 2789 docs, 1147 queries\n",
      "\n",
      "üìÇ Loading pre-chunked corpus from notebook 2...\n",
      "   Source: ../data/chunked_corpus\n",
      "  ‚úÖ Loaded 6036 pre-chunked chunks\n",
      "  üìã Method used: preserve_tables (2048/200)\n",
      "   üìà Expansion: 2789 docs ‚Üí 6036 chunks (2.16x)\n",
      "\n",
      "üî¢ Encoding chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89702ec1a8c446c7a935c6e205092eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/378 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 6036 chunks\n",
      "\n",
      "üîç Building FAISS index...\n",
      "   ‚úÖ Index built with 6036 vectors\n",
      "\n",
      "üî§ Building BM25 index...\n",
      "   ‚úÖ BM25 index built\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f88a2d6cdc14575a00977d135f4c5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 1147 queries\n",
      "\n",
      "üîé Retrieving and reranking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fe637f3d6d4c8a99ddb69ee87d8579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieve+Rerank:   0%|          | 0/1147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Generated 11470 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.4190\n",
      "   Queries evaluated: 1147\n",
      "\n",
      "======================================================================\n",
      "üìä Processing: FINQABENCH\n",
      "======================================================================\n",
      "  Loaded 92 docs, 100 queries\n",
      "\n",
      "üìÇ Loading pre-chunked corpus from notebook 2...\n",
      "   Source: ../data/chunked_corpus\n",
      "  ‚úÖ Loaded 419 pre-chunked chunks\n",
      "  üìã Method used: recursive (512/50)\n",
      "   üìà Expansion: 92 docs ‚Üí 419 chunks (4.55x)\n",
      "\n",
      "üî¢ Encoding chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a0e5843fc646059ab7287540a27c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 419 chunks\n",
      "\n",
      "üîç Building FAISS index...\n",
      "   ‚úÖ Index built with 419 vectors\n",
      "\n",
      "üî§ Building BM25 index...\n",
      "   ‚úÖ BM25 index built\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4388312f8754adfb4b9e0a5342f3364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 100 queries\n",
      "\n",
      "üîé Retrieving and reranking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1e41b7576a4eb5becc349e757c314e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieve+Rerank:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Generated 1000 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.8759\n",
      "   Queries evaluated: 100\n",
      "\n",
      "======================================================================\n",
      "üìä Processing: MULTIHEIRTT\n",
      "======================================================================\n",
      "  Loaded 10475 docs, 974 queries\n",
      "\n",
      "üìÇ Loading pre-chunked corpus from notebook 2...\n",
      "   Source: ../data/chunked_corpus\n",
      "  ‚úÖ Loaded 11241 pre-chunked chunks\n",
      "  üìã Method used: preserve_tables (3000/300)\n",
      "   üìà Expansion: 10475 docs ‚Üí 11241 chunks (1.07x)\n",
      "\n",
      "üî¢ Encoding chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658686b4cd634130aabea045de1d14ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 11241 chunks\n",
      "\n",
      "üîç Building FAISS index...\n",
      "   ‚úÖ Index built with 11241 vectors\n",
      "\n",
      "üî§ Building BM25 index...\n",
      "   ‚úÖ BM25 index built\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e18976d12e74d00a185f184d914cb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 974 queries\n",
      "\n",
      "üîé Retrieving and reranking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40192a03d614dbcb345e518c4e39fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieve+Rerank:   0%|          | 0/974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Generated 9740 results\n",
      "\n",
      "üìä Evaluating...\n",
      "   NDCG@10: 0.1435\n",
      "   Queries evaluated: 974\n",
      "\n",
      "======================================================================\n",
      "üìä Processing: TATQA\n",
      "======================================================================\n",
      "  Loaded 2756 docs, 1663 queries\n",
      "\n",
      "üìÇ Loading pre-chunked corpus from notebook 2...\n",
      "   Source: ../data/chunked_corpus\n",
      "  ‚úÖ Loaded 2756 pre-chunked chunks\n",
      "  üìã Method used: no_chunking\n",
      "   üìà Expansion: 2756 docs ‚Üí 2756 chunks (1.00x)\n",
      "\n",
      "üî¢ Encoding chunks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d24c2b6247b40ec91465ff9579fb07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 2756 chunks\n",
      "\n",
      "üîç Building FAISS index...\n",
      "   ‚úÖ Index built with 2756 vectors\n",
      "\n",
      "üî§ Building BM25 index...\n",
      "   ‚úÖ BM25 index built\n",
      "\n",
      "üéØ Processing queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcb7556c45744faba6912611a28fee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoded 1663 queries\n",
      "\n",
      "üîé Retrieving and reranking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e551c39dca402ba1beeea80adf4b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieve+Rerank:   0%|          | 0/1663 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = []\n",
    "all_eval = {}\n",
    "failed = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING OPTIMAL CHUNKING PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for dataset in CONFIG['datasets']:\n",
    "    try:\n",
    "        df_res, metrics = process_dataset_with_optimal_chunking(dataset, CONFIG)\n",
    "        all_results.append(df_res)\n",
    "        if metrics:\n",
    "            all_eval[dataset] = metrics\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error processing {dataset}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        failed.append(dataset)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úÖ Pipeline completed: {len(all_results)}/{len(CONFIG['datasets'])} datasets\")\n",
    "if failed:\n",
    "    print(f\"‚ùå Failed datasets: {failed}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e326343a",
   "metadata": {},
   "source": [
    "## üìä Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab3d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä EVALUATION SUMMARY (NDCG@10)\n",
      "======================================================================\n",
      "\n",
      "CONVFINQA      : 0.4858 (421 queries)\n",
      "\n",
      "FINANCEBENCH   : 0.7362 (150 queries)\n",
      "\n",
      "FINDER         : 0.3953 (216 queries)\n",
      "\n",
      "FINQA          : 0.4570 (1147 queries)\n",
      "\n",
      "FINQABENCH     : 0.8662 (100 queries)\n",
      "\n",
      "MULTIHEIRTT    : 0.1467 (974 queries)\n",
      "\n",
      "TATQA          : 0.4768 (1663 queries)\n",
      "\n",
      "======================================================================\n",
      "üìà WEIGHTED AVERAGE NDCG@10: 0.4168\n",
      "======================================================================\n",
      "\n",
      "üéØ Performance vs Baseline:\n",
      "   Baseline (no chunking): 0.3280\n",
      "   Optimal chunking: 0.4168\n",
      "   Improvement: +0.0888 (+27.1%)\n",
      "\n",
      "‚úÖ GOOD! Solid improvement!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "if all_eval:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä EVALUATION SUMMARY (NDCG@10)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    total_ndcg = 0\n",
    "    total_queries = 0\n",
    "    \n",
    "    for ds, m in sorted(all_eval.items()):\n",
    "        print(f\"\\n{ds.upper():15s}: {m['NDCG@10']:.4f} ({m['num_queries']} queries)\")\n",
    "        total_ndcg += m['NDCG@10'] * m['num_qrels']\n",
    "        total_queries += m['num_qrels']\n",
    "    \n",
    "    if total_queries > 0:\n",
    "        avg_ndcg = total_ndcg / total_queries\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üìà WEIGHTED AVERAGE NDCG@10: {avg_ndcg:.4f}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Compare with baseline\n",
    "        baseline = 0.328  # Original baseline\n",
    "        gain = avg_ndcg - baseline\n",
    "        gain_pct = (gain / baseline) * 100\n",
    "        \n",
    "        print(f\"\\nüéØ Performance vs Baseline:\")\n",
    "        print(f\"   Baseline (no chunking): {baseline:.4f}\")\n",
    "        print(f\"   Optimal chunking: {avg_ndcg:.4f}\")\n",
    "        print(f\"   Improvement: +{gain:.4f} ({gain_pct:+.1f}%)\")\n",
    "        \n",
    "        # Performance tier\n",
    "        if avg_ndcg >= 0.58:\n",
    "            print(f\"\\nüèÜ EXCELLENT! Likely TOP 3 performance!\")\n",
    "        elif avg_ndcg >= 0.50:\n",
    "            print(f\"\\n‚úÖ VERY GOOD! Strong improvement!\")\n",
    "        elif avg_ndcg >= 0.40:\n",
    "            print(f\"\\n‚úÖ GOOD! Solid improvement!\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è More tuning needed\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No evaluation metrics available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde0faf9",
   "metadata": {},
   "source": [
    "## üíæ Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bc2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Submission saved: submission_optimal_chunking.csv\n",
      "   Total entries: 46,710\n",
      "   Unique queries: 4,671\n",
      "\n",
      "üìã Sample results:\n",
      "     query_id  corpus_id\n",
      "0   qd4982518  dd4c4f7aa\n",
      "1   qd4982518  dd4bb016e\n",
      "2   qd4982518  dd4b9f7f6\n",
      "3   qd4982518  dd4bb5506\n",
      "4   qd4982518  dd4b87d18\n",
      "5   qd4982518  dd4be45d6\n",
      "6   qd4982518  dd4bd3790\n",
      "7   qd4982518  dd4c0119a\n",
      "8   qd4982518  dd4b89cbc\n",
      "9   qd4982518  dd4971510\n",
      "10  qd49795a8  dd4befb5c\n",
      "11  qd49795a8  dd4c05bc8\n",
      "12  qd49795a8  dd4bd7b9c\n",
      "13  qd49795a8  dd4979602\n",
      "14  qd49795a8  dd4c4cf78\n",
      "\n",
      "üîç Validation:\n",
      "   Results per query: {10: 4671}\n",
      "   ‚úÖ All queries have exactly 10 results\n"
     ]
    }
   ],
   "source": [
    "if all_results:\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    submission_df = final_df[['query_id', 'corpus_id']]\n",
    "    \n",
    "    submission_df.to_csv(CONFIG['output_file'], index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Submission saved: {CONFIG['output_file']}\")\n",
    "    print(f\"   Total entries: {len(submission_df):,}\")\n",
    "    print(f\"   Unique queries: {submission_df['query_id'].nunique():,}\")\n",
    "    \n",
    "    print(f\"\\nüìã Sample results:\")\n",
    "    print(submission_df.head(15))\n",
    "    \n",
    "    # Validation\n",
    "    counts = submission_df.groupby('query_id').size()\n",
    "    print(f\"\\nüîç Validation:\")\n",
    "    print(f\"   Results per query: {dict(counts.value_counts().sort_index())}\")\n",
    "    \n",
    "    if (counts == 10).all():\n",
    "        print(f\"   ‚úÖ All queries have exactly 10 results\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Warning: Some queries don't have 10 results\")\n",
    "        print(f\"   Queries with != 10 results: {sum(counts != 10)}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No results to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf4148b",
   "metadata": {},
   "source": [
    "## üéØ Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca450b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéâ OPTIMAL CHUNKING PIPELINE COMPLETED!\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Key Features:\n",
      "   1. Optimal chunking (512 chars, 50 overlap)\n",
      "   2. Table-aware chunking\n",
      "   3. Fixed-size chunking method\n",
      "   4. BGE-large embeddings\n",
      "   5. BGE-reranker-v2-m3 (SOTA)\n",
      "   6. Hybrid search (Dense + BM25)\n",
      "   7. Max-score aggregation\n",
      "\n",
      "üìä Final NDCG@10: 0.4168\n",
      "\n",
      "üíæ Output: submission_optimal_chunking.csv\n",
      "\n",
      "üöÄ Next: Upload to Kaggle!\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ OPTIMAL CHUNKING PIPELINE COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ Key Features:\")\n",
    "print(\"   1. Optimal chunking (512 chars, 50 overlap)\")\n",
    "print(\"   2. Table-aware chunking\")\n",
    "print(\"   3. Fixed-size chunking method\")\n",
    "print(\"   4. BGE-large embeddings\")\n",
    "print(\"   5. BGE-reranker-v2-m3 (SOTA)\")\n",
    "print(\"   6. Hybrid search (Dense + BM25)\")\n",
    "print(\"   7. Max-score aggregation\")\n",
    "\n",
    "if all_eval:\n",
    "    total_ndcg = sum(m['NDCG@10'] * m['num_qrels'] for m in all_eval.values())\n",
    "    total_queries = sum(m['num_qrels'] for m in all_eval.values())\n",
    "    if total_queries > 0:\n",
    "        avg = total_ndcg / total_queries\n",
    "        print(f\"\\nüìä Final NDCG@10: {avg:.4f}\")\n",
    "\n",
    "print(f\"\\nüíæ Output: {CONFIG['output_file']}\")\n",
    "print(f\"\\nüöÄ Next: Upload to Kaggle!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933847d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financerag_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
