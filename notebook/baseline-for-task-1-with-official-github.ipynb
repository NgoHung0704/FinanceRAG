{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICAIF 2024 Finance-RAG Challenge Baseline\n",
    "\n",
    "This notebook demonstrates a **baseline solution** for the **ICAIF 2024 Finance-RAG Challenge**. The goal of the challenge is to create a **Retrieval-Augmented Generation (RAG)** system for financial data. Participants are tasked with developing systems that retrieve relevant documents from a large corpus and provide accurate, context-aware responses to user queries.\n",
    "\n",
    "---\n",
    "\n",
    "## System Components\n",
    "\n",
    "The system is divided into two main components:\n",
    "\n",
    "1. **Retrieval**: Retrieves relevant financial documents from a large corpus based on a user query.\n",
    "2. **Reranking**: Refines the ranking of the retrieved documents to ensure the most relevant information is prioritized.\n",
    "\n",
    "---\n",
    "\n",
    "## Model Overview\n",
    "\n",
    "This baseline notebook uses a combination of `SentenceTransformer` and `CrossEncoder` models to perform these tasks:\n",
    "\n",
    "- The **retrieval model** is responsible for encoding both the queries and documents into embeddings.\n",
    "- The **reranking model** evaluates the relevance of the retrieved documents and reorders them accordingly.\n",
    "\n",
    "In this example, the baseline task used is **FinDER**, which is one of the seven available tasks in the FinanceRAG project. The retrieval model used is `intfloat/e5-large-v2`, and the reranking is performed using `cross-encoder/ms-marco-MiniLM-L-12-v2`. Both of these models can be substituted with other models supported by the `sentence_transformers` library for performance experimentation.\n",
    "\n",
    "---\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is to provide a **solid foundation** for participants to build more advanced solutions for the challenge. Feel free to customize the task, retrieval model, and reranking model as needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Repository Setup and Environment Configuration\n",
    "\n",
    "You can find the repository for this project on GitHub [here](https://github.com/JiH00nKw0n/FinanceRAG).\n",
    "\n",
    "To clone the repository and set up the environment, follow these steps:\n",
    "\n",
    "### 1. Clone the repository:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/linq-rag/FinanceRAG.git\n",
    "cd FinanceRAG\n",
    "```\n",
    "\n",
    "### 2. Set up the Python environment:\n",
    "\n",
    "#### If using `venv` (Python 3.11 or higher required):\n",
    "\n",
    "```bash\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate  # On Windows use .venv\\Scripts\u0007ctivate\n",
    "pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### If using `conda`:\n",
    "\n",
    "```bash\n",
    "conda create -n financerag python=3.11\n",
    "conda activate financerag\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "You should now be ready to run the baseline notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to Python path to find the financerag package\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory (FinanceRAG root) to the path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T21:00:55.706522Z",
     "iopub.status.busy": "2025-12-21T21:00:55.706105Z",
     "iopub.status.idle": "2025-12-21T21:00:55.982151Z",
     "shell.execute_reply": "2025-12-21T21:00:55.980013Z",
     "shell.execute_reply.started": "2025-12-21T21:00:55.706490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/FinanceRAG/financerag_env/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# --------------------------------------\n",
    "# Import required libraries for document retrieval, reranking, and logging setup.\n",
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "\n",
    "from financerag.rerank import CrossEncoderReranker\n",
    "from financerag.retrieval import DenseRetrieval, SentenceTransformerEncoder\n",
    "from financerag.tasks import FinDER\n",
    "\n",
    "# Setup basic logging configuration to show info level messages.\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:15.808338Z",
     "iopub.status.busy": "2024-10-04T14:51:15.807849Z",
     "iopub.status.idle": "2024-10-04T14:51:23.956758Z",
     "shell.execute_reply": "2024-10-04T14:51:23.955721Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.common.loader:Loading Corpus...\n",
      "INFO:financerag.common.loader:Loaded 13867 Documents.\n",
      "INFO:financerag.common.loader:Corpus Example: {'id': 'ADBE20230004', 'title': 'ADBE OVERVIEW', 'text': 'Adobe is a global technology company with a mission to change the world through personalized digital experiences. For over four decades, Adobe’s innovations have transformed how individuals, teams, businesses, enterprises, institutions, and governments engage and interact across all types of media. Our products, services and solutions are used around the world to imagine, create, manage, deliver, measure, optimize and engage with content across surfaces and fuel digital experiences. We have a diverse user base that includes consumers, communicators, creative professionals, developers, students, small and medium businesses and enterprises. We are also empowering creators by putting the power of artificial intelligence (“AI”) in their hands, and doing so in ways we believe are responsible. Our products and services help unleash creativity, accelerate document productivity and power businesses in a digital world.'}\n",
      "INFO:financerag.common.loader:Loading Queries...\n",
      "INFO:financerag.common.loader:Loaded 216 Queries.\n",
      "INFO:financerag.common.loader:Query Example: {'id': 'q00001', 'text': 'What are the service and product offerings from Microsoft'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize FinDER Task\n",
    "# --------------------------\n",
    "# In this baseline example, we are using the FinDER task, one of the seven available tasks in this project.\n",
    "# If you want to use a different task, for example, 'OtherTask', you can change the task initialization as follows:\n",
    "#\n",
    "# Example:\n",
    "# from financerag.tasks import OtherTask\n",
    "# finder_task = OtherTask()\n",
    "#\n",
    "# For this baseline, we proceed with FinDER.\n",
    "finder_task = FinDER()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:23.961016Z",
     "iopub.status.busy": "2024-10-04T14:51:23.960728Z",
     "iopub.status.idle": "2024-10-04T14:51:39.063618Z",
     "shell.execute_reply": "2024-10-04T14:51:39.062302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Initialize DenseRetriever model\n",
    "# -------------------------------------\n",
    "# Initialize the retrieval model using SentenceTransformers. This model will be responsible\n",
    "# for encoding both the queries and documents into embeddings.\n",
    "#\n",
    "# You can replace 'intfloat/e5-large-v2' with any other model supported by SentenceTransformers.\n",
    "# For example: 'BAAI/bge-large-en-v1.5', 'Linq-AI-Research/Linq-Embed-Mistral', etc.\n",
    "encoder_model = SentenceTransformerEncoder(\n",
    "    model_name_or_path='intfloat/e5-large-v2',\n",
    "    query_prompt='query: ',\n",
    "    doc_prompt='passage: ',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:39.068549Z",
     "iopub.status.busy": "2024-10-04T14:51:39.068124Z",
     "iopub.status.idle": "2024-10-04T14:54:07.488228Z",
     "shell.execute_reply": "2024-10-04T14:54:07.486678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Perform retrieval\n",
    "# ---------------------\n",
    "# Use the model to retrieve relevant documents for given queries.\n",
    "retrieval_model = DenseRetrieval(\n",
    "    model=encoder_model\n",
    ")\n",
    "\n",
    "retrieval_result = finder_task.retrieve(\n",
    "    retriever=retrieval_model\n",
    ")\n",
    "\n",
    "# Print a portion of the retrieval results to verify the output.\n",
    "print(f\"Retrieved results for {len(retrieval_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in retrieval_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:07.495914Z",
     "iopub.status.busy": "2024-10-04T14:54:07.494072Z",
     "iopub.status.idle": "2024-10-04T14:54:09.186831Z",
     "shell.execute_reply": "2024-10-04T14:54:09.185722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Initialize CrossEncoder Reranker\n",
    "# --------------------------------------\n",
    "# The CrossEncoder model will be used to rerank the retrieved documents based on relevance.\n",
    "#\n",
    "# You can replace 'cross-encoder/ms-marco-MiniLM-L-12-v2' with any other model supported by CrossEncoder.\n",
    "# For example: 'cross-encoder/ms-marco-TinyBERT-L-2', 'cross-encoder/stsb-roberta-large', etc.\n",
    "reranker = CrossEncoderReranker(\n",
    "    model=CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:09.190909Z",
     "iopub.status.busy": "2024-10-04T14:54:09.190659Z",
     "iopub.status.idle": "2024-10-04T14:54:54.978852Z",
     "shell.execute_reply": "2024-10-04T14:54:54.977781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Perform reranking\n",
    "# -------------------------\n",
    "# Rerank the top 100 retrieved documents using the CrossEncoder model.\n",
    "reranking_result = finder_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=retrieval_result,\n",
    "    top_k=100,  # Rerank the top 100 documents\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Print a portion of the reranking results to verify the output.\n",
    "print(f\"Reranking results for {len(reranking_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in reranking_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:54.98932Z",
     "iopub.status.busy": "2024-10-04T14:54:54.9891Z",
     "iopub.status.idle": "2024-10-04T14:54:55.005455Z",
     "shell.execute_reply": "2024-10-04T14:54:55.004477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 7: Save results\n",
    "# -------------------\n",
    "# Save the results to the specified output directory as a CSV file.\n",
    "output_dir = './results'\n",
    "finder_task.save_results(output_dir=output_dir)\n",
    "\n",
    "# Confirm the results have been saved.\n",
    "print(f\"Results have been saved to {output_dir}/FinDER/results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9767247,
     "sourceId": 85594,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "financerag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
