{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICAIF 2024 Finance-RAG Challenge Baseline\n",
    "\n",
    "This notebook demonstrates a **baseline solution** for the **ICAIF 2024 Finance-RAG Challenge**. The goal of the challenge is to create a **Retrieval-Augmented Generation (RAG)** system for financial data. Participants are tasked with developing systems that retrieve relevant documents from a large corpus and provide accurate, context-aware responses to user queries.\n",
    "\n",
    "---\n",
    "\n",
    "## System Components\n",
    "\n",
    "The system is divided into two main components:\n",
    "\n",
    "1. **Retrieval**: Retrieves relevant financial documents from a large corpus based on a user query.\n",
    "2. **Reranking**: Refines the ranking of the retrieved documents to ensure the most relevant information is prioritized.\n",
    "\n",
    "---\n",
    "\n",
    "## Model Overview\n",
    "\n",
    "This baseline notebook uses a combination of `SentenceTransformer` and `CrossEncoder` models to perform these tasks:\n",
    "\n",
    "- The **retrieval model** is responsible for encoding both the queries and documents into embeddings.\n",
    "- The **reranking model** evaluates the relevance of the retrieved documents and reorders them accordingly.\n",
    "\n",
    "In this example, the baseline task used is **FinDER**, which is one of the seven available tasks in the FinanceRAG project. The retrieval model used is `intfloat/e5-large-v2`, and the reranking is performed using `cross-encoder/ms-marco-MiniLM-L-12-v2`. Both of these models can be substituted with other models supported by the `sentence_transformers` library for performance experimentation.\n",
    "\n",
    "---\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is to provide a **solid foundation** for participants to build more advanced solutions for the challenge. Feel free to customize the task, retrieval model, and reranking model as needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Repository Setup and Environment Configuration\n",
    "\n",
    "You can find the repository for this project on GitHub [here](https://github.com/JiH00nKw0n/FinanceRAG).\n",
    "\n",
    "To clone the repository and set up the environment, follow these steps:\n",
    "\n",
    "### 1. Clone the repository:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/linq-rag/FinanceRAG.git\n",
    "cd FinanceRAG\n",
    "```\n",
    "\n",
    "### 2. Set up the Python environment:\n",
    "\n",
    "#### If using `venv` (Python 3.11 or higher required):\n",
    "\n",
    "```bash\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate  # On Windows use .venv\\Scripts\u0007ctivate\n",
    "pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### If using `conda`:\n",
    "\n",
    "```bash\n",
    "conda create -n financerag python=3.11\n",
    "conda activate financerag\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "You should now be ready to run the baseline notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add parent directory to Python path to find the financerag package\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory (FinanceRAG root) to the path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important: Kernel Restart Required\n",
    "\n",
    "**If you've just cloned this repository or updated the code**, you need to restart the kernel to load the modifications:\n",
    "\n",
    "1. Click on \"Kernel\" menu â†’ \"Restart Kernel\"\n",
    "2. Or use the keyboard shortcut\n",
    "\n",
    "The code has been modified to use local data files from the `data/` folder instead of trying to download from Hugging Face Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T21:00:55.706522Z",
     "iopub.status.busy": "2025-12-21T21:00:55.706105Z",
     "iopub.status.idle": "2025-12-21T21:00:55.982151Z",
     "shell.execute_reply": "2025-12-21T21:00:55.980013Z",
     "shell.execute_reply.started": "2025-12-21T21:00:55.706490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/FinanceRAG/financerag_env/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# --------------------------------------\n",
    "# Import required libraries for document retrieval, reranking, and logging setup.\n",
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "\n",
    "from financerag.rerank import CrossEncoderReranker\n",
    "from financerag.retrieval import DenseRetrieval, SentenceTransformerEncoder\n",
    "from financerag.tasks import FinDER\n",
    "\n",
    "# Setup basic logging configuration to show info level messages.\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:15.808338Z",
     "iopub.status.busy": "2024-10-04T14:51:15.807849Z",
     "iopub.status.idle": "2024-10-04T14:51:23.956758Z",
     "shell.execute_reply": "2024-10-04T14:51:23.955721Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File /workspaces/FinanceRAG/data/finder/corpus.jsonl not present! Please provide an accurate file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Step 2: Initialize FinDER Task\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# In this baseline example, we are using the FinDER task, one of the seven available tasks in this project.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# For this baseline, we proceed with FinDER.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m finder_task = \u001b[43mFinDER\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/FinanceRAG/financerag/tasks/FinDERTask.py:44\u001b[39m, in \u001b[36mFinDER.__init__\u001b[39m\u001b[34m(self, use_local_data)\u001b[39m\n\u001b[32m     19\u001b[39m         dataset_config = {\n\u001b[32m     20\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mLinq-AI-Research/FinanceRAG\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msubset\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mFinDER\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m         }\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mself\u001b[39m.metadata: TaskMetadata = TaskMetadata(\n\u001b[32m     25\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mFinDER\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mPrepared for competition from Linq\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     bibtex_citation=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     43\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/FinanceRAG/financerag/tasks/BaseTask.py:65\u001b[39m, in \u001b[36mBaseTask.__init__\u001b[39m\u001b[34m(self, metadata)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28mself\u001b[39m.rerank_results: Optional[Dict] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m.generate_results: Optional[Dict] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/FinanceRAG/financerag/tasks/BaseTask.py:97\u001b[39m, in \u001b[36mBaseTask.load_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# Check if loading from local data or HuggingFace Hub\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdata_folder\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dataset_config:\n\u001b[32m     92\u001b[39m     \u001b[38;5;66;03m# Load from local files\u001b[39;00m\n\u001b[32m     93\u001b[39m     corpus, queries = \u001b[43mHFDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata_folder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     99\u001b[39m     \u001b[38;5;66;03m# Load from HuggingFace Hub\u001b[39;00m\n\u001b[32m    100\u001b[39m     dataset_path = dataset_config[\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/FinanceRAG/financerag/common/loader.py:122\u001b[39m, in \u001b[36mHFDataLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[33;03mLoads both the corpus and query datasets. If the datasets are not already loaded,\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[33;03mthey are loaded from the specified source (either local files or Hugging Face repository).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    119\u001b[39m \u001b[33;03m    `Tuple[Dataset, Dataset]`: A tuple containing the loaded corpus and queries datasets.\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hf_repo:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_in\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m.check(file_in=\u001b[38;5;28mself\u001b[39m.query_file, ext=\u001b[33m\"\u001b[39m\u001b[33mjsonl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.corpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/FinanceRAG/financerag/common/loader.py:104\u001b[39m, in \u001b[36mHFDataLoader.check\u001b[39m\u001b[34m(file_in, ext)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[33;03mCheck if the given file exists and has the correct extension.\u001b[39;00m\n\u001b[32m     95\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m \u001b[33;03m    `ValueError`: If the file does not exist or if the extension does not match.\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(file_in).exists():\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    105\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFile \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m not present! Please provide an accurate file.\u001b[39m\u001b[33m\"\u001b[39m.format(file_in)\n\u001b[32m    106\u001b[39m     )\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_in.endswith(ext):\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    110\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFile \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m must have the extension \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(file_in, ext)\n\u001b[32m    111\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: File /workspaces/FinanceRAG/data/finder/corpus.jsonl not present! Please provide an accurate file."
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize FinDER Task\n",
    "# --------------------------\n",
    "# In this baseline example, we are using the FinDER task, one of the seven available tasks in this project.\n",
    "# If you want to use a different task, for example, 'OtherTask', you can change the task initialization as follows:\n",
    "#\n",
    "# Example:\n",
    "# from financerag.tasks import OtherTask\n",
    "# finder_task = OtherTask()\n",
    "#\n",
    "# For this baseline, we proceed with FinDER.\n",
    "finder_task = FinDER()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:23.961016Z",
     "iopub.status.busy": "2024-10-04T14:51:23.960728Z",
     "iopub.status.idle": "2024-10-04T14:51:39.063618Z",
     "shell.execute_reply": "2024-10-04T14:51:39.062302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Initialize DenseRetriever model\n",
    "# -------------------------------------\n",
    "# Initialize the retrieval model using SentenceTransformers. This model will be responsible\n",
    "# for encoding both the queries and documents into embeddings.\n",
    "#\n",
    "# You can replace 'intfloat/e5-large-v2' with any other model supported by SentenceTransformers.\n",
    "# For example: 'BAAI/bge-large-en-v1.5', 'Linq-AI-Research/Linq-Embed-Mistral', etc.\n",
    "encoder_model = SentenceTransformerEncoder(\n",
    "    model_name_or_path='intfloat/e5-large-v2',\n",
    "    query_prompt='query: ',\n",
    "    doc_prompt='passage: ',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:51:39.068549Z",
     "iopub.status.busy": "2024-10-04T14:51:39.068124Z",
     "iopub.status.idle": "2024-10-04T14:54:07.488228Z",
     "shell.execute_reply": "2024-10-04T14:54:07.486678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Perform retrieval\n",
    "# ---------------------\n",
    "# Use the model to retrieve relevant documents for given queries.\n",
    "retrieval_model = DenseRetrieval(\n",
    "    model=encoder_model\n",
    ")\n",
    "\n",
    "retrieval_result = finder_task.retrieve(\n",
    "    retriever=retrieval_model\n",
    ")\n",
    "\n",
    "# Print a portion of the retrieval results to verify the output.\n",
    "print(f\"Retrieved results for {len(retrieval_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in retrieval_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:07.495914Z",
     "iopub.status.busy": "2024-10-04T14:54:07.494072Z",
     "iopub.status.idle": "2024-10-04T14:54:09.186831Z",
     "shell.execute_reply": "2024-10-04T14:54:09.185722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Initialize CrossEncoder Reranker\n",
    "# --------------------------------------\n",
    "# The CrossEncoder model will be used to rerank the retrieved documents based on relevance.\n",
    "#\n",
    "# You can replace 'cross-encoder/ms-marco-MiniLM-L-12-v2' with any other model supported by CrossEncoder.\n",
    "# For example: 'cross-encoder/ms-marco-TinyBERT-L-2', 'cross-encoder/stsb-roberta-large', etc.\n",
    "reranker = CrossEncoderReranker(\n",
    "    model=CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:09.190909Z",
     "iopub.status.busy": "2024-10-04T14:54:09.190659Z",
     "iopub.status.idle": "2024-10-04T14:54:54.978852Z",
     "shell.execute_reply": "2024-10-04T14:54:54.977781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Perform reranking\n",
    "# -------------------------\n",
    "# Rerank the top 100 retrieved documents using the CrossEncoder model.\n",
    "reranking_result = finder_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=retrieval_result,\n",
    "    top_k=100,  # Rerank the top 100 documents\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Print a portion of the reranking results to verify the output.\n",
    "print(f\"Reranking results for {len(reranking_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in reranking_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T14:54:54.98932Z",
     "iopub.status.busy": "2024-10-04T14:54:54.9891Z",
     "iopub.status.idle": "2024-10-04T14:54:55.005455Z",
     "shell.execute_reply": "2024-10-04T14:54:55.004477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 7: Save results\n",
    "# -------------------\n",
    "# Save the results to the specified output directory as a CSV file.\n",
    "output_dir = './results'\n",
    "finder_task.save_results(output_dir=output_dir)\n",
    "\n",
    "# Confirm the results have been saved.\n",
    "print(f\"Results have been saved to {output_dir}/FinDER/results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9767247,
     "sourceId": 85594,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "financerag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
